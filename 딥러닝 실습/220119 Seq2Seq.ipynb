{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch():\n",
    "    input_batch, output_batch, target_batch = [], [], []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        # nstep 길이에 맞춰 'P' 넣어주기\n",
    "        for i in range(2):\n",
    "            seq[i] = seq[i] + 'P'*(n_step - len(seq[i]))\n",
    "\n",
    "        input = [num_dic[n] for n in seq[0]]\n",
    "        output = [num_dic[n] for n in ('S' + seq[1])]\n",
    "        target = [num_dic[n] for n in (seq[1] + 'E')]\n",
    "\n",
    "        input_batch.append(np.eye(n_class)[input])\n",
    "        output_batch.append(np.eye(n_class)[output])\n",
    "        target_batch.append(target) # not one-hot\n",
    "\n",
    "    # make tensor\n",
    "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ib size : torch.Size([6, 5, 29])\n",
      "ob size : torch.Size([6, 6, 29])\n",
      "tb size : torch.Size([6, 6])\n"
     ]
    }
   ],
   "source": [
    "ib, ob, tb = make_batch()\n",
    "print('ib size :', ib.shape)\n",
    "print('ob size :', ob.shape)\n",
    "print('tb size :', tb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_data : [['manPP', 'women'], ['black', 'white'], ['kingP', 'queen'], ['girlP', 'boyPP'], ['upPPP', 'downP'], ['highP', 'lowPP']]\n",
      "n_class : 29\n",
      "seq : ['manPP', 'women']\n",
      "input : ['m', 'a', 'n', 'P', 'P']  ->  [15, 3, 16, 2, 2]\n",
      "-- 2 \n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]]\n",
      "output : ['S', 'w', 'o', 'm', 'e', 'n']  ->  [0, 25, 17, 15, 7, 16]\n",
      "target : ['w', 'o', 'm', 'e', 'n', 'E']  ->  [25, 17, 15, 7, 16, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('seq_data :', seq_data)\n",
    "print('n_class :', n_class)\n",
    "\n",
    "for seq in seq_data:\n",
    "        for i in range(2):\n",
    "            seq[i] = seq[i] + 'P'*(n_step - len(seq[i]))\n",
    "        print('seq :', seq)\n",
    "\n",
    "        input = [num_dic[n] for n in seq[0]]\n",
    "        output = [num_dic[n] for n in ('S' + seq[1])]\n",
    "        target = [num_dic[n] for n in (seq[1] + 'E')]\n",
    "\n",
    "        print('input :', [n for n in seq[0]], ' -> ', input)\n",
    "        print('output :', [n for n in ('S' + seq[1])], ' -> ', output)\n",
    "        print('target :', [n for n in (seq[1] + 'E')], ' -> ', target, end='\\n\\n')\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ...  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('After ... ', np.eye(29)[[22, 3, 16, 2, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_testbatch(input_word):\n",
    "    input_batch, output_batch = [], []\n",
    "\n",
    "    input_w = input_word + 'P'*(n_step - len(input_word))\n",
    "    input = [num_dic[n] for n in input_w]\n",
    "    output = [num_dic[n] for n in 'S'+'P'*n_step]\n",
    "\n",
    "    # np.eye : 대각행렬\n",
    "    input_batch = np.eye(n_class)[input]\n",
    "    output_batch = np.eye(n_class)[output]\n",
    "    return torch.FloatTensor(input_batch).unsqueeze(0), torch.FloatTensor(output_batch).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 shape :  torch.Size([16, 32, 3])\n",
      "transpose 후, torch.Size([32, 16, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(16, 32, 3)\n",
    "print('x의 shape : ', x.shape)\n",
    "\n",
    "y = x.transpose(0,1)\n",
    "print('transpose 후,', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 부모 클래스 호출 : (하위 클래스 이름, 객체)\n",
    "        super(Seq2Seq, self).__init__()  \n",
    "\n",
    "        # n_class = 29, n_hidden = 128\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.fc = nn.Linear(n_hidden, n_class)\n",
    "\n",
    "    def forward(self, enc_input, enc_hidden, dec_input):\n",
    "        # enc_input = [max_len(=n_step), batch_size, n_class]\n",
    "        # dec_input = [max_len(=n_step), batch_size, n_class]\n",
    "        enc_input = enc_input.transpose(0, 1)\n",
    "        dec_input = dec_input.transpose(0, 1)\n",
    "\n",
    "        # enc_states : [num_layers(=1)*num_directions(=1), batch_size, n_hidden]\n",
    "        _, enc_states = self.enc_cell(enc_input, enc_hidden)\n",
    "\n",
    "        # outputs : [max_len+1(=6), batch_size, num_directions(=1)*n_hidden(=128)]\n",
    "        outputs, _ = self.dec_cell(dec_input, enc_states)\n",
    "\n",
    "        # model : [max_len+1(=6), batch_size, n_class]\n",
    "        model = self.fc(outputs)   \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SULJEE~1\\AppData\\Local\\Temp/ipykernel_8084/1848509464.py:17: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000 cost = 0.003337\n",
      "Epoch : 2000 cost = 0.000910\n",
      "Epoch : 3000 cost = 0.000388\n",
      "Epoch : 4000 cost = 0.000195\n",
      "Epoch : 5000 cost = 0.000106\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    n_step = 5\n",
    "    n_hidden = 128\n",
    "\n",
    "    char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz']\n",
    "    num_dic = {n:i for i, n in enumerate(char_arr)}\n",
    "    seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low']]\n",
    "\n",
    "    n_class = len(num_dic)\n",
    "    batch_size = len(seq_data)\n",
    "\n",
    "    model = Seq2Seq()\n",
    "\n",
    "    # Cost function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # batch 생성\n",
    "    input_batch, output_batch, target_batch = make_batch()\n",
    "\n",
    "    for epoch in range(5000):\n",
    "        hidden = torch.zeros(1, batch_size, n_hidden)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(input_batch, hidden, output_batch)\n",
    "        output = output.transpose(0,1)\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(0, len(target_batch)):\n",
    "            loss += criterion(output[i], target_batch[i])\n",
    "\n",
    "        if (epoch+1)%1000 == 0:\n",
    "            print('Epoch :', '%04d'%(epoch+1), 'cost =', '{:6f}'.format(loss))\n",
    "\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(word):\n",
    "    input_batch, output_batch = make_testbatch(word)\n",
    "\n",
    "    hidden = torch.zeros(1,1,n_hidden)\n",
    "    output = model(input_batch, hidden, output_batch)\n",
    "\n",
    "    predict = output.data.max(2, keepdim=True)[1]\n",
    "    decoded = [char_arr[i] for i in predict]\n",
    "    end = decoded.index('E')\n",
    "    translated = ''.join(decoded[:end])\n",
    "\n",
    "    return translated.replace('P', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "975adaa33bdd6241222e23cb1553fcd899050d10dc86e144a6598f19462bc660"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('zeze': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
