{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch():\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    for sen in sentences:\n",
    "        # ex) I like dog\n",
    "        word = sen.split()  # space tokenizer\n",
    "        input = [word_dict[n] for n in word[:-1]]   # 앞에 N개의 단어 (I - 3, like - 0)\n",
    "        target = word_dict[word[-1]]       # 예측할 단어 (dog - 6)\n",
    "\n",
    "        input_batch.append(input)\n",
    "        target_batch.append(target)\n",
    "\n",
    "    return input_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class NNLM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNLM, self).__init__()\n",
    "        # nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.C = nn.Embedding(n_class, m)    \n",
    "\n",
    "        # nn.Linear(input_dim, output_dim, bias=T or F(bias 학습 X))\n",
    "        self.H = nn.Linear(n_step*m, n_hidden, bias=False)  \n",
    "        self.d = nn.Parameter(torch.ones(n_hidden))\n",
    "\n",
    "        self.U = nn.Linear(n_hidden, n_class, bias=False)\n",
    "        self.W = nn.Linear(n_step*m, n_class, bias=False)\n",
    "        self.b = nn.Parameter(torch.ones(n_class))\n",
    "\n",
    "    def forward(self, X):   \n",
    "        # 입력 : [n_step, m]\n",
    "        # Embedding layer\n",
    "        X = self.C(X)   # [batch_size, n_step, m]\n",
    "\n",
    "        # Projection Layer\n",
    "        X = X.view(-1, n_step*m)    # [batch_size, n_step*m]\n",
    "\n",
    "        # Hidden Layer\n",
    "        tanh = torch.tanh(self.d + self.H(X))   # [batch_size, n_hidden]\n",
    "\n",
    "        # Output Layer\n",
    "        output = self.b + self.W(X) + self.U(tanh)  # [batch_size, n_class]\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_class : 7\n"
     ]
    }
   ],
   "source": [
    "n_step = 2\n",
    "n_hidden = 2    \n",
    "m = 2   # embedding_dim\n",
    "\n",
    "sentences = [\"I like dog\", \"I love coffee\", \"I hate milk\"]\n",
    "\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))    # ['like', 'milk', 'coffee', 'I', 'hate', 'love', 'dog']\n",
    "word_dict = {w:i for i,w in enumerate(word_list)}   # ex) 'like' : 0\n",
    "number_dict = {i:w for i,w in enumerate(word_list)} # ex) 0 : 'like'\n",
    "n_class = len(word_dict)    # number of Vocabulary\n",
    "print('n_class :', n_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 선언\n",
    "model = NNLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()   # cost function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)    # 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_batch : [[3, 0], [3, 5], [3, 4]]\n",
      "target_batch : [6, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "input_batch, target_batch = make_batch()\n",
    "print('input_batch :', input_batch)\n",
    "print('target_batch :', target_batch)\n",
    "\n",
    "input_batch = torch.LongTensor(input_batch)\n",
    "target_batch = torch.LongTensor(target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After input : torch.Size([3, 2]), target : torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print('After input : {}, target : {}'.format(input_batch.shape, target_batch.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 cost = 0.079087\n",
      "Epoch: 2000 cost = 0.012405\n",
      "Epoch: 3000 cost = 0.004127\n",
      "Epoch: 4000 cost = 0.001769\n",
      "Epoch: 5000 cost = 0.000858\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(5000):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input_batch)     # 순전파\n",
    "\n",
    "    # output : [batch_size, n_class]\n",
    "    # target : [batch_size]\n",
    "    loss = criterion(output, target_batch)  # 손실함수\n",
    "    if (epoch+1)%1000==0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "    \n",
    "    loss.backward()     # 역전파\n",
    "    optimizer.step()    # learning rate만큼 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predict = model(input_batch).data.max(1, keepdim=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict : tensor([[6],\n",
      "        [2],\n",
      "        [1]]) , shape= torch.Size([3, 1])\n",
      "After squeeze() : tensor([6, 2, 1]) torch.Size([3])\n",
      "Tensor  tensor(6) 의 item :  6\n"
     ]
    }
   ],
   "source": [
    "print('predict :', predict, ', shape=', predict.shape)\n",
    "\n",
    "sqz = predict.squeeze()\n",
    "print('After squeeze() :', sqz, sqz.shape)\n",
    "\n",
    "print('Tensor ', sqz[0],'의 item : ', sqz[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'like'], ['I', 'love'], ['I', 'hate']] → ['dog', 'coffee', 'milk']\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print([sen.split()[:2] for sen in sentences], '→', [number_dict[n.item()] for n in predict.squeeze()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "## Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.W = nn.Linear(voc_size, embedding_size, bias=False)   \n",
    "        self.WT = nn.Linear(embedding_size, voc_size, bias=False)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # X : [batch_size, voc_size]\n",
    "        hidden_layer = self.W(X)    # hidden_layer : [batch_size, embedding_size]\n",
    "        output_layer = self.WT(hidden_layer)    # output_layer : [batch_size, voc_size]\n",
    "        return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp : 2\n",
      "tmp : 5\n"
     ]
    }
   ],
   "source": [
    "# replace : True(복원추출 - 모든 원소가 뽑힐 확률이 동일함), False(비복원추출)\n",
    "# np.random.chocie(모집단, size, replace=T or F)\n",
    "tmp_idx = np.random.choice(range(32), 2, replace=False)\n",
    "for tmp in tmp_idx:\n",
    "    print('tmp :', tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(8)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch():\n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False)      # 0~31(len(skip_grams)) 중 2(batch_size)개를 랜덤으로 뽑음 (겹치치 않음)\n",
    "\n",
    "    for i in random_index:  \n",
    "        random_inputs.append(np.eye(voc_size)[skip_grams[i][0]])    # target\n",
    "        random_labels.append(skip_grams[i][1])  # context word\n",
    "\n",
    "    return random_inputs, random_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2  # mini-batch size\n",
    "embedding_size = 2  # embedding size\n",
    "sentences = [\"apple banana fruit\", \"banana orange fruit\", \"orange banana fruit\", \"dog cat animal\", \"cat monkey animal\", \"monkey dog animal\"]\n",
    "\n",
    "word_sequence = \" \".join(sentences).split()\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))    # 중복제거\n",
    "word_dict = {w:i for i,w in enumerate(word_list)}\n",
    "idx2word = {i:w for i,w in enumerate(word_list)}\n",
    "voc_size = len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word dict : {'fruit': 0, 'apple': 1, 'monkey': 2, 'animal': 3, 'banana': 4, 'dog': 5, 'cat': 6, 'orange': 7}\n",
      "vocab size : 8\n",
      "word sequence : ['apple', 'banana', 'fruit', 'banana', 'orange', 'fruit', 'orange', 'banana', 'fruit', 'dog', 'cat', 'animal', 'cat', 'monkey', 'animal', 'monkey', 'dog', 'animal']\n"
     ]
    }
   ],
   "source": [
    "print('word dict :', word_dict)\n",
    "print('vocab size :', voc_size)\n",
    "print('word sequence :', word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make skip-gram of one size window\n",
    "skip_grams = []\n",
    "for i in range(1, len(word_sequence)-1):\n",
    "    target = word_dict[word_sequence[i]]\n",
    "    context = [word_dict[word_sequence[i-1]], word_dict[word_sequence[i+1]]]\n",
    "    for w in context:\n",
    "        skip_grams.append([target, w])  # [target, 앞 단어], [target, 뒤 단어]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip_gram : 32\n"
     ]
    }
   ],
   "source": [
    "print('skip_gram :', len(skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()   # Cost function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 cost = 2.029262\n",
      "Epoch: 2000 cost = 1.532641\n",
      "Epoch: 3000 cost = 1.231635\n",
      "Epoch: 4000 cost = 1.488697\n",
      "Epoch: 5000 cost = 0.712782\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(5000):\n",
    "    input_batch, target_batch = random_batch()\n",
    "    \n",
    "    input_batch = torch.Tensor(input_batch)\n",
    "    target_batch = torch.LongTensor(target_batch)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input_batch)\n",
    "\n",
    "    # output : [batch_size, voc_size]\n",
    "    # target_batch : [batch_size] (LongTensor, not one-hot)\n",
    "    loss = criterion(output, target_batch)\n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,label in enumerate(word_list):\n",
    "    W,WT = model.parameters()\n",
    "    x,y = W[0][i].item(), W[1][i].item()\n",
    "    plt.scatter(x,y)\n",
    "    plt.annotate(label, xy=(x,y), xytext=(5,2), textcoords='offset points', ha='right', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 8])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_id = [[word_dict[i] for i in [\"banana\", \"cat\"]]]\n",
    "sample = []\n",
    "for id in sample_id:\n",
    "    sample.append(np.eye(voc_size)[id])\n",
    "\n",
    "sample = torch.Tensor(sample)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin :  banana -> fruit\n",
      "origin :  cat -> animal\n"
     ]
    }
   ],
   "source": [
    "output = model(sample)\n",
    "\n",
    "# output_layer : [batch_size, voc_size]\n",
    "for i in range(2):\n",
    "    print('origin : ', idx2word[sample_id[0][i]], end=' -> ')\n",
    "    target = torch.argmax(output[0][i])\n",
    "    #print(output[0][i])\n",
    "    print(idx2word[target.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "975adaa33bdd6241222e23cb1553fcd899050d10dc86e144a6598f19462bc660"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('zeze': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
