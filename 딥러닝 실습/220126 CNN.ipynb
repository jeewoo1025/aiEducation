{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "###  Initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly 초기화 (정규분포)\n",
    "w1 = tf.Variable(tf.random_normal(shape=[784, 256]))\n",
    "\n",
    "# Uniform distribution 초기화 (범위 안에 같은 확률로 나옴)\n",
    "w2 = tf.Variable(tf.random_uniform(shape=[784, 256]))\n",
    "\n",
    "# Xavier 초기화 ()\n",
    "# fan_in : 입력값, fan_out : 출력값\n",
    "# w = np.random.rand(fan_in, fan_out) / np.sqrt(fan_in)\n",
    "w3 = tf.get_variable(\"w3\", shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### check_point\n",
    "\n",
    "어떤 모델을 학습을 통해서 원하는 결과가 나왔다! <br>\n",
    "모델을 원하는 시간에 호출하고 싶은데 그러면 어떻게 해야되지? <br>\n",
    "매번 학습하면 시간과 비용이 많이 들기 때문에 (비효율성) → 학습된 모델 파라미터 값을 저장한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "\n",
    "# model\n",
    "\n",
    "# loss function and optimizer\n",
    "\n",
    "ckpt_path = \"C:/\"\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # checkpoint 불러옴\n",
    "    saver.restore(sess, ckpt_path)\n",
    "\n",
    "    # training\n",
    "\n",
    "    # checkpoint 저장함\n",
    "    saver.save(sess, ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN의 등장배경\n",
    "\n",
    "필기체 인식 문제를 Fully-connected Neural Network로 풀어보면? <br>\n",
    "할 수는 있다! 그런데 전체 픽셀을 모두 확인하기 때문에 매우 비효율적이다. <br>\n",
    "또한 뒤틀림, 끊김 등 다양한 변화가 있기 때문에 결과값이 다 달라진다. <br>\n",
    "<br>\n",
    "\n",
    "요약하지만, <br>\n",
    "Fully-connected layer의 구조적 문제로 인한 문제 발생! <br>\n",
    "* 이미지는 (가로, 세로, 채널)의 형태를 가지는 3차원 배열\n",
    "* FC Layer의 입력은 항상 1차원 배열\n",
    "* FC Layer의 모든 값들이 오나전 연결되어 있으므로 전체 픽셀의 모든 관계를 다 계산해야함\n",
    " <br> <br>\n",
    "이미지의 3차원 배열 형상을 무시하고 1차원 배열로 flatten해서 학습\n",
    " <br> <br>\n",
    "이미지의 전체적인 관계를 <b>고려하지 못해서 변형된 data에 매우 취약함 (Topology)</b>  <br>\n",
    "이미지의 특성 픽셀은 <b>주변 픽셀과 관련이 있다는 특성을 잃어버림 (Locality)</b>  <br>\n",
    "→ 이미지를 조금만 변형해도 아예 다른 object로 인식하게 됨 <br>\n",
    "<br>\n",
    "모든 이미지마다 학습해야 해서 망의 크기, 변수의 개수, 학습 시간 ↑ <br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Convolution\n",
    "합성곱은 하나의 함수와 또 다른 함수를 반전 이동한 값을 곱한 다음, \n",
    "구간에 대해 적분하여 새로운 함수를 구하는 수학 연산자이다.\n",
    "<br><br>\n",
    "\n",
    "### Channel\n",
    "- 입력 데이터의 Channel의 수와 필터의 Channel 수가 일치해야 함\n",
    "- 필터의 개수가 아웃풋의 Channel을 결정\n",
    "<br><br>\n",
    "\n",
    "## Stride\n",
    "필터를 적용하는 위치의 간격\n",
    "```code\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1,1,1,1], padding='VALID')\n",
    "```\n",
    "<br><br>\n",
    "\n",
    "## Padding\n",
    "Convolution으로 인한 Image 모서리 부분 정보 손실 방지를 위해 입력데이터 주변을 특정값으로 채우는 것 (일반적으로 Zero Padding 사용)\n",
    "<br><br>\n",
    "\n",
    "## Pooling\n",
    "가로 세로 방향의 공간을 줄이는 연산\n",
    "- 출력의 해상도를 낮춰 변형이나 이동에 대한 민감도를 감소\n",
    "- 이미지의 크기를 줄이기 때문에 학습할 노드의 수가 줄어들어 학습속도를 높이는 효과\n",
    "- 하지만, 정보의 손실이 일어남\n",
    "- CNN에선느 Max Pooling 사용\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.get_variable(name=name + \"_W\", shape=[filter_size, filter_size, fin, fout])\n",
    "b = tf.get_variable(name=name + \"_b\", shape=[fout], initializer=tf.contrib.layers.xavier_initializer(0.0))\n",
    "C = tf.nn.conv2d(din, W, strides=[1,1,1,1], padding='SAME')\n",
    "R = tf.nn.relu(tt.nn.bias_add(C,b))\n",
    "pool = tf.nn.max_pool(R, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv layer 1 + Pooling layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suljeewoo\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\suljeewoo\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\suljeewoo\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\suljeewoo\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\suljeewoo\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\suljeewoo\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SULJEE~1\\AppData\\Local\\Temp/ipykernel_16008/3268641682.py:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\suljeewoo\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\suljeewoo\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\suljeewoo\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\suljeewoo\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\suljeewoo\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(?, 28, 28, 1) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\suljeewoo\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "W1 = tf.get_variable(name=\"W1\", shape=[3,3,1,32], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.get_variable(name=\"b1\", shape=[32], initializer=tf.contrib.layers.xavier_initializer())\n",
    "C1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding='SAME')\n",
    "L1 = tf.nn.relu(tf.nn.bias_add(C1, b1))\n",
    "L1_pool = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 28, 28, 32) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.get_variable(name=\"W2\", shape=[3,3,32,64], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.get_variable(name=\"b2\", shape=[64], initializer=tf.contrib.layers.xavier_initializer())\n",
    "C2 = tf.nn.conv2d(L1_pool, W2, strides=[1,1,1,1], padding='SAME')\n",
    "L2 = tf.nn.relu(tf.nn.bias_add(C2, b2))\n",
    "L2_pool = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "# flatten 들어가기 전 size를 맞춰줌\n",
    "L2_flat = tf.reshape(L2_pool, [-1, 64*7*7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_1:0' shape=(?, 7, 7, 64) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.get_variable(name='W3', shape=[64*7*7, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.get_variable(name='b3', shape=[10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "logits = tf.nn.bias_add(tf.matmul(L2_flat, W3), b3) \n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(cost) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 cost= 2.352836215\n",
      "Epoch : 2 cost= 2.341277432\n",
      "Epoch : 3 cost= 2.330308377\n",
      "Epoch : 4 cost= 2.320164851\n",
      "Epoch : 5 cost= 2.310808979\n",
      "Epoch : 6 cost= 2.302091691\n",
      "Epoch : 7 cost= 2.293953197\n",
      "Epoch : 8 cost= 2.286159678\n",
      "Epoch : 9 cost= 2.278518824\n",
      "Epoch : 10 cost= 2.271012173\n",
      "Epoch : 11 cost= 2.263439117\n",
      "Epoch : 12 cost= 2.255743415\n",
      "Epoch : 13 cost= 2.247949215\n",
      "Epoch : 14 cost= 2.239957472\n",
      "Epoch : 15 cost= 2.231648603\n",
      "Accuracy 0.3353\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict={X:batch_xs, Y:batch_ys})\n",
    "            avg_cost += c/total_batch\n",
    "        print(\"Epoch :\", '%d'%(epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "    print(\"Accuracy\", sess.run(accuracy, feed_dict={X: mnist.test.images, Y:mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3354ff924175df80e4a6667ab2133fd90d36bf3622cc87205a6c43221272165c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
