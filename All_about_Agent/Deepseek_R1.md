# Deepseek-R1
- Paper: [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948)
- Github: [deepseek-ai/DeepSeek-R1](https://github.com/deepseek-ai/DeepSeek-R1)
- Scaled up the RLVR on coding, mathematics, science, logic reasoning (=ëª¨ë‘ verifiable rewardsê°€ ìˆëŠ” tasks)
- System Prompt
  <img width="772" height="202" alt="image" src="https://github.com/user-attachments/assets/5e21e783-5b06-4f06-bb55-ee2af45101a7" />


### ğŸš¨ ì¤‘ìš” Point
- **dataë¥¼ ì–»ì–´ë‚´ëŠ” ê³¼ì • (ìƒì„±, í•„í„°ë§)ì´ ê°€ì¥ ì¤‘ìš”í•œ í¬ì¸íŠ¸**
  - Cold Start Long CoT Data, Reasoning Data, Non-Reasoning Data, Combined SFT Data
- R1ì„ í›ˆë ¨ì‹œí‚¤ëŠ” í•µì‹¬ dataë¥¼ ê°€ì§€ê³  DeepSeek-R1-Distill-Qwen/Llama-*Bë¥¼ í•™ìŠµì‹œí‚´ (Distillation)
  - "ì¤‘ê°„ ì‚¬ê³  ê³¼ì •"ì„ ì•Œë ¤ì£¼ëŠ” dataë¥¼ í° DeepSeek ëª¨ë¸ì´ ë§Œë“¦ (= ì–´ë–¤ ì‹ìœ¼ë¡œ ì‚¬ê³ í•˜ë©´ ì¢‹ì€ ê²ƒì´ë‹¤! ë¼ëŠ” data ìƒì„±). ê·¸ dataë¥¼ ì‘ì€ modelì—ê²Œ ì•Œë ¤ì¤Œ
- **non-linear reasoning working!** modelì´ ì‚¬ê³ í•˜ë©´ì„œ, ì´ì „ì— ì§„í–‰í–ˆì—ˆë˜ stepì„ ë‹¤ì‹œ ê²€í† í•˜ê³  í‹€ë ¸ìœ¼ë©´ ìˆ˜ì •í•˜ê³  ë¥¼ ì§ì ‘ ì•ˆ ì•Œë ¤ì¤Œì—ë„ ë¶ˆêµ¬í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë°œí˜„ì´ ë¨
  - ì¦‰, non-linear / linear reasoning ë°œí˜„ ì—¬ë¶€ê°€ ì¤‘ìš”í•œ íŒë‹¨
  - ì§ˆë¬¸: ê·¸ëŸ¼ ì™œ ì´ì „ì—ëŠ” non-linear reaosningì´ ì•ˆë¬ì„ê¹Œ? (__Why did RLVR suddenly work?__) ë‹µë³€: [Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs](https://arxiv.org/abs/2503.01307)
    - 4ê°€ì§€ Cognitive behaviorë¥¼ ì •ì˜ (Verifications, Subgoal setting, Backtracking, Backward Chaining) ë° ì¸¡ì • â†’ Qwenì€ í•¨. Llamaì€ ì•ˆí•¨. â†’ ê·¸ í›„, RLVRë¥¼ í•™ìŠµí–ˆì„ ë•Œ ìœ„ì˜ í–‰ë™ë“¤ì„ Qwenë§Œ CoT ê¸¸ì´ë„ ê¸¸ì–´ì§€ê³  ì„±ëŠ¥ë„ í›¨ì”¬ ì˜¬ë¼ê°. ë˜í•œ, Llamaì—ê²Œ cognitive behaviorë¥¼ ê°€ë¥´ì¹˜ë©´ RLì´ ì˜ ë™ì‘í•¨.
    - ê²°ë¡ : **Llama2ì™€ Llama3ì€ non-linear reasoningì— í•„ìš”í•œ cognitive behaviorê°€ ì¡´ì¬í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì´ë‹¤.**
  - ì§ˆë¬¸: ì™œ ê·¸ëŸ¬ë©´ Llamaì—ëŠ” ì—†ì—ˆì„ê¹Œ? ë‹µë³€: [Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs](https://arxiv.org/abs/2503.01307)
    - Llamaì˜ train datasetì—ëŠ” non-linear reasoningì´ ì—†ì—ˆê¸° ë•Œë¬¸! (ì¶”ì •: LlamaëŠ” [OpenWebMath](https://arxiv.org/abs/2310.06786)ì™€ [FineMath](https://arxiv.org/abs/2502.02737) datasetì„ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ìŒ. OpenWebMathì—ì„œëŠ” ì‚¬ê³ ì˜ íë¦„ì„ ë‹´ì€ ê³¼ì •ì´ ë‹´ê²¨ì ¸ ìˆëŠ”(ex. ì´ë ‡ê²Œ í•´ë´¤ë”ë‹ˆ ì•ˆë˜ë„¤...? ì´ë ‡ê²Œ í•´ë´ì•¼ì§€) math datasetì„.) 
- Majority vote (ëŒ€í‘œì ì¸ test-time scaling ê¸°ë²•)ì€ ì—¬ì „íˆ ìœ íš¨í•œ ë°©ë²•ì„ì„ ë³´ì—¬ì¤Œ
- Process reward models (PRM)ê³¼ MCTSê°€ ì˜ ë™ì‘í•˜ì§€ ì•Šë‹¤ê³  ë³´ê³ í•¨. Language Generation ê²½ìš°ì—ëŠ” ë°”ë‘‘ê³¼ ë‹¬ë¦¬, MCTSì—ì„œ ì‹¤ì œë¡œ ìˆ˜í–‰í•´ì•¼ ë˜ëŠ” Tree Search ê·œëª¨ê°€ ì»¤ì„œ ì´ë“ì´ ë˜ì§€ ì•ŠëŠ”ë‹¤ê³  ì¶”ì¸¡í•¨.
  - PRM: ì¤‘ê°„ ê³¼ì •ì„ ì²´í¬í•˜ê³  í‰ê°€í•´ì„œ í›ˆë ¨í•˜ëŠ” ëª¨ë¸

### ğŸ¤® ì•„ì‰¬ìš´ Point
- "í•„í„°ë§ í•˜ëŠ” mechanism" (ì„¬ì„¸í•˜ê²Œ ì¢‹ì€ CoT dataë¥¼ ê³¨ë¼ë‚´ëŠ” ê²ƒ)ì€ ê³µìœ  ì•ˆ í•¨
- length normalization biasê°€ ë°œìƒí•¨

#### ğŸ«  ì™¸ì „
- Test-time scaling with budget forcing = ì§€ê¸ˆ ë‹¹ì¥ ë‹µì„ í•´!ë¼ê³  ê°•ìš” (ex. "Final Answer: "). ì—°ì†ì ìœ¼ë¡œ Thinking timeì„ ì¡°ì ˆí•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œì•ˆ
  - Paper: [s1: Simple test-time scaling](https://arxiv.org/abs/2501.19393)
- Dr. GRPO = ì˜¬ë°”ë¥¸ ë‹µì´ ì§§ì•„ì§€ë„ë¡ rewardë¥¼ ì£¼ëŠ” ë°©ë²•.
  - Motivation > Length normalization bias: GRPOì—ì„œ í’€ì´(ë‹µ)ì´ ê¸¸ì–´ì§€ëŠ” ê²½ìš°ì—ëŠ” ë‹µì´ correctí•˜ë“  incorrectë“  lossì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ”ë‹¤. ëª¨ë¸ ì…ì¥ì—ì„œëŠ” ë¹¨ë¦¬ í’€ì–´ë²„ë¦¬ë©´ rewardë¥¼ ë°›ìŒ. í•˜ì§€ë§Œ í¬ê¸°ë¥¼ í•  ê²½ìš°ì—ëŠ” ëŠì„ì—†ì´ ê³„ì† ê¸¸ê²Œ í’€ì´í•˜ë‹¤ê°€ ë‹µì„ ì¶œë ¥í•˜ë©´ ë°›ëŠ” penaltyê°€ ìµœì†Œí™”.
  - Paper: [Understanding R1-Zero-Like Training: A Critical Perspective](https://arxiv.org/abs/2503.20783) 

<br>

## ğŸ“Ÿ ë¶„ì„ Blog
- [DeepSeek-R1ì— ê´€í•œ ë¹„ì£¼ì–¼ ê°€ì´ë“œ](https://tulip-phalange-a1e.notion.site/DeepSeek-R1-189c32470be2801c94b6e5648735447d)

<br>

## ğŸ‘©ğŸ»â€ğŸ’» Code
- huggingface/Fully open reproduction of DeepSeek-R1: https://github.com/huggingface/open-r1
- Building DeepSeek R1 from Scratch: https://github.com/FareedKhan-dev/train-deepseek-r1
