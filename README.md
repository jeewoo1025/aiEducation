# ğŸ“š aiEducation
ML/DL, NLP ê´€ë ¨ ê³µë¶€ ê¸°ë¡

* ê¸°ê°„ : 2021 ~ Present
<br><br>

## ğŸ” ë…¼ë¬¸ ì°¾ëŠ” Tips
1. [paperswithcode](https://paperswithcode.com/sota)ì—ì„œ tasks ìœ„ì£¼ë¡œ SOTA ë…¼ë¬¸ì„ ë³´ì—¬ì¤Œ <br> 
   âœ” Most implemented paperë¥¼ ì°¸ê³ í•˜ë©´ ì–´ë–¤ ë…¼ë¬¸ì´ ê°€ì¥ ë§ì´ ì¸ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸ê°€ëŠ¥í•¨ <br><br> 
2. githubì—ì„œ task ê²€ìƒ‰ <br> ì´ë•Œ `awesome [íŠ¹ì • task]`ë¡œ ê²€ìƒ‰í•˜ë©´ curated list ê²Œì‹œë¬¼ì„ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆë‹¤. <br> ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œ ë…¼ë¬¸ì¸ì§€ëŠ” Star ê°¯ìˆ˜ë‚˜ fork ìˆ˜ë¡œ íŒë³„ê°€ëŠ¥í•¨
   <br> <br>

3. EMNLP, ACL ë“± Impact Factorê°€ ë†’ì€ í•™íšŒë“¤ì—ì„œ ë°œí‘œí•œ ë…¼ë¬¸ë“¤ë¡œ ìµœì‹  íŠ¸ë Œë“œë¥¼ ì•Œ ìˆ˜ ìˆë‹¤
<br><br>

## ğŸƒ ë…¼ë¬¸ ì‘ì„±ë²•
### Overleaf
LatexëŠ” Conference, Journal ë“± ë…¼ë¬¸ì„ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ë¬¸ì„œ ì‘ì„± ì‹œìŠ¤í…œì´ë‹¤. ëŒ€ë‹¤ìˆ˜ì˜ ë…¼ë¬¸ë“¤ì´ Latextë¥¼ ì´ìš©í•´ ì‘ì„±ë˜ê³ , ê³µìœ ë˜ì–´ ê´€ë¦¬ë˜ì–´ ìˆë‹¤. 
ì´ëŸ¬í•œ Latex í”„ë¡œê·¸ë¨ì„ ì‚¬ìš©í•´ ë…¼ë¬¸ í”„ë¡œì íŠ¸ë¥¼ í¸í•˜ê²Œ ê´€ë¦¬í•˜ê³  ê³µìœ í•  ìˆ˜ ìˆë„ë¡ í•´ì£¼ëŠ” ëŒ€í‘œì ì¸ ì„œë¹„ìŠ¤ë¡œ `Overleaf`ê°€ ìˆë‹¤. 
`Overleaf > Template`ì—ì„œ ê²€ìƒ‰ì„ í†µí•´ ì œì¶œí•  í•™íšŒì˜ ë…¼ë¬¸ Templateë¥¼ ë‹¤ìš´ë°›ì•„ ì‘ì„±í•˜ë©´ ëœë‹¤. 
* ì‚¬ì´íŠ¸ : https://www.overleaf.com/project
* ì‚¬ìš©ë²• : [ë‚˜ë™ë¹ˆ > ì´ê³µê³„ì—´ í•™ìƒì„ ìœ„í•œ Latex ì‘ì„± ë°©ë²• Feat. Overleaf](https://ndb796.tistory.com/342)

<br><br>

## â­ NLP í•„ìˆ˜ ë…¼ë¬¸ (ë…„ë„ ìˆœ)
* Word2Vec (ICLR 2013) : [Paper Link](https://arxiv.org/abs/1301.3781)
* Seq2Seq (NIPS 2014) : [Paper Link](https://arxiv.org/abs/1409.3215) / [Seq2Seq.pdf](https://github.com/jeewoo1025/aiEducation/files/7446757/Seq2Seq.pdf) / [colab](https://colab.research.google.com/drive/1Jg4AYB-Ku4tuSIRchU8REvwqlsfsPD81#scrollTo=1OSgbkh0Vkq7)
* Attetion (ICLR 2015) : [Paper Link]() 
* Transformer (NIPS 2017) : [Paper Link](https://arxiv.org/abs/1706.03762v5)
    * [Pytorch tutorial Harvard's NLP group](http://nlp.seas.harvard.edu/2018/04/03/attention.html)

* GPT (2018) : [Paper Link](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) 
* BERT (NACCL 2019) : [Paper Link](https://arxiv.org/abs/1910.13461v1) 
* GPT-2 (2019) : [Paper Link](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
* GPT-3 (NIPS 2020) : [Paper Link](https://arxiv.org/abs/2005.14165) 
* BART (ACL 2020) : [Paper Link](https://arxiv.org/abs/1910.13461)
<br>
<br>

### âœ” Summary
||Base model|Pretraining Tasks|
|:---:|:---:|:---:|
|ELMo|two-layer biLSTM|next token prediction|
|GPT|Transformer decoder|next token prediction|
|BERT|Transformer encoder|mask language model + next sentence prediction|
|ALBERT|same as BERT but light-weighted|mask language model + sentence order prediction|
|GPT-2|Transformer decoder|next token prediction|
|RoBERTa|same as BERT|mask language model (dynamic masking)|
|T5|Transformer encoder + decoder|pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a text-to-text format.|
|GPT-3|Transformer decoder|next token prediction|
|BART|BERT encoder + GPT decoder|reconstruct text from a noised version|
|ELECTRA|same as BERT|replace token detection|

<br>
<br>

### âœ” Open QA
* Danqi Chen github : https://github.com/danqi
* [ACL2020 Tutorial: Open-Domain Question Answering](https://github.com/danqi/acl2020-openqa-tutorial) 
<br>
<br>

### âœ” í…ìŠ¤íŠ¸ ìš”ì•½ 
* Must-read paper : https://github.com/jeewoo1025/Text-Summarization-Repo
* ê°•í•„ì„± êµìˆ˜ë‹˜ì˜ DSBA ì—°êµ¬ì‹¤ ìë£Œ : [github](https://github.com/pilsung-kang/text-analytics) / [youtube](https://www.youtube.com/channel/UCPq01cgCcEwhXl7BvcwIQyg)
* mathsyouthì˜ curated list: [awesome-text-summarization](https://github.com/mathsyouth/awesome-text-summarization)

#### Dataset
* [CNN-Daily Mail](https://github.com/abisee/cnn-dailymail)
<br>
<br>

## ğŸ“Š ì„±ëŠ¥ ì¸¡ì • ë°©ë²•
1. **BLEU** 
* Bilingual Evaluation Understudy
* ê¸°ê³„ë²ˆì—­ì˜ ì„±ëŠ¥ì´ ì–¼ë§ˆë‚˜ ë›°ì–´ë‚œê°€ë¥¼ ì¸¡ì •í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•¨
* ê¸°ê³„ ë²ˆì—­ ê²°ê³¼ì™€ ì‚¬ëŒì´ ì§ì ‘ ë²ˆì—­í•œ ê²°ê³¼ê°€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ ë¹„êµí•˜ì—¬ ë²ˆì—­ì— ëŒ€í•œ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ë°©ë²•
* ë†’ì„ ìˆ˜ë¡ ì„±ëŠ¥ì´ ë” ì¢‹ë‹¤
* ì¥ì  : ì–¸ì–´ì— êµ¬ì• ë°›ì§€ ì•ŠìŒ, ê³„ì‚° ì†ë„ê°€ ë¹ ë¦„
<br>
<br>

2. **ROUGE / ROUGE 2.0**
* Recall-Oriented Understudy for Gisting Evaluation
* github : https://github.com/bheinzerling/pyrouge
* Text summarizationì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•¨
* ROUGEëŠ” reference summaryì™€ ëª¨ë¸ì´ ìƒì„±í•œ summary ì‚¬ì´ì— ê²¹ì¹˜ëŠ” tokenì´ ë§ì„ìˆ˜ë¡ scoreê°€ ë†’ì•„ì§„ë‹¤. í•˜ì§€ë§Œ, ë‹¤ë¥¸ ë‹¨ì–´ë¼ë„ ë™ì¼í•œ ì˜ë¯¸ë¥¼ ê°€ì§€ëŠ” ë¬¸ì¥ì„ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” í•œê³„ì ì´ ìˆì–´ì„œ ì´ë¥¼ ë³´ì™„í•´ì„œ ë‚˜ì˜¨ê²Œ ROUGE 2.0ì´ë‹¤.
* ROUGE 2.0ì€ synonymous(ë™ì˜ì–´)ì™€ topic coverageë¥¼ í¬í•¨í•˜ì—¬ ìœ„ì˜ issueë¥¼ ë³´ì™„í•˜ì˜€ë‹¤. â†’ `ROUGE - {NN | Topic | TopicUniq} + Synonyms`
* ê·¸ëŸ¬ë‚˜ ì—¬ì „íˆ ì™„ë²½í•˜ê²Œ score ë§¤ê¸¸ ìˆ˜ ì—†ì§€ë§Œ í˜„ì¬ê¹Œì§€ ê°€ì¥ ì¢‹ì€ Evaluation ë°©ë²•ì´ë¼ê³  í‰ê°€ë°›ëŠ”ë‹¤.
<br>
<br>

## ğŸ“¬ íˆ¬ê³  
* **workshop** 
  * ëŒ€ê·œëª¨ í•™íšŒëŠ” ì‹œì‘í•  ë•Œ ì•ë’¤ë¡œ í•˜ë£¨ ê·œëª¨ì˜ workshopë¥¼ ì§„í–‰í•œë‹¤. ëª©ì ì€ ë³¸ í•™íšŒ ì°¸ì„ìë“¤ì´ specificí•œ í‚¤ì›Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ëª¨ì—¬ì„œ ì§„í–‰í•˜ëŠ” ì‘ì€ í•™íšŒê°™ì€ ëŠë‚Œ. ë³´í†µ ë³¸ í•™íšŒ ë‚´ê¸° ì• ë§¤í•˜ê±°ë‚˜ Working in Processë¥¼ ê³µìœ í•˜ê³  í”¼ë“œë°± ë°›ëŠ” ìë¦¬ì´ê¸°ë„ í•˜ë‹¤.
  * Call for workshopì„ ì—´ì–´ committeeê°€ pass/non pass ì—¬ë¶€ë¥¼ ì£¼ê³  ë‹¤ì‹œ ê·¸ workshopì—ì„œ ë°›ì„ ë…¼ë¬¸ì— ëŒ€í•œ ê³µê³ ë¥¼ ë‚¸ë‹¤. 
<br>

* **tutorial** 
  * ìƒˆë¡œìš´ ë…¼ë¬¸ì„ ì œì•ˆí•˜ê¸°ë³´ë‹¤ëŠ” ê¸‰ ë¶€ìƒí•œ ìƒˆë¡œìš´ ì£¼ì œì— ëŒ€í•œ ê°œë¡ ì ì¸ ê°•ì˜ë¥¼ í•˜ëŠ” í•˜ë£¨ ê·œëª¨ì˜ ì„¸ì…˜ (e.g. ACL 2020 open-domain QA tutorial)
<br>

* **full/short paper**
  * í•™íšŒë§ˆë‹¤ ê¸°ëŒ€í•˜ëŠ” long/short paperì— ëŒ€í•œ ìŠ¤í™ì´ ìˆê¸° ë•Œë¬¸ì—, call for paperë¥¼ ì°¸ê³ í•˜ëŠ” ê±¸ ì¶”ì²œí•œë‹¤. í†µìƒì ìœ¼ë¡œ short paperëŠ” long paperì— ë¹„í•´ ìƒë‹¹íˆ ì§§ê³  long paper íˆ¬ê³ ê°€ ë” ì¸ì • ë°›ëŠ”ë‹¤. 
  * NAACL call for papers 2022 
    * Long paper : (8 pages) substantial, original, completed and unpublished work
    * Short paper : (4 pages) original and unpublished work
<br>
<br>

## Dataset Download
Origin link : https://github.com/ShichaoSun/ConAbsSum
### XSum
* hungging face link :  https://huggingface.co/datasets/xsum
* get dataset
```
wget https://cdn-datasets.huggingface.co/summarization/xsum.tar.gz
tar -xzvf xsum.tar.gz
```
<br>

### CNN/DM
* hugging face link : https://huggingface.co/datasets/cnn_dailymail
* get dataset
```
wget https://cdn-datasets.huggingface.co/summarization/pegasus_data/cnn_dailymail.tar.gz
tar -xzvf cnn_dailymail.tar.gz
mv cnn_dailymail/validation.source cnn_dailymail/val.source 
mv cnn_dailymail/validation.target cnn_dailymail/val.target 
```
<br>

##  ğŸ“  Study
### ë‚˜ë™ë¹ˆ
* [ê¼¼ê¼¼í•œ ë”¥ëŸ¬ë‹ ë…¼ë¬¸ ë¦¬ë·°ì™€ ì½”ë“œ ì‹¤ìŠµ](https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice)
* [ì»´í“¨í„° ê³µí•™ê³¼ë¥¼ ìœ„í•œ ìµœì‹  ë…¼ë¬¸ ì°¾ì•„ ì½ëŠ” ë°©ë²• ì •ë¦¬](https://www.youtube.com/watch?v=FPcdxHCxH_o)
<br><br>

### Deep Learning 
* [PyTorchë¡œ ì‹œì‘í•˜ëŠ” ë”¥ ëŸ¬ë‹ ì…ë¬¸](https://wikidocs.net/book/2788)
* [BERT ëŒì•„ë³´ê¸°](https://docs.likejazz.com/bert/)
<br><br>

### NLP basic
* [oh! suz's NLP Cookbook](https://www.ohsuz.dev/nlp-cookbook)
* [Jeonsworld's NLP ê´€ë ¨ ë…¼ë¬¸ ë¦¬ë·° í¬ìŠ¤íŒ…](https://jeonsworld.github.io/)
* [ì›”ê°„ ìì—°ì–´ì²˜ë¦¬ - Facebook](https://www.facebook.com/monthly.nlp?hc_ref=ART_4x3Knm-Y_6Rw38lFMtWmKZ8SdL4fWSzm2I9CiaYwJAtFIHk9mP_T7mK69NC8V2A&fref=nf&__xts__[0]=68.ARD8SbISh91tv-3NTdye910Za6oW4Nkfc9S3jAAX3n9xWPQjLdTDJA9eCQh_J10Y3ROSXAR5k_zgzd7q77OEgRaN0yMMkp4XdSPzROUANUkOJajbcUBhbaPtD_riFOG2cAWkFIAJ35CE3XQvrYj4246-Ggebd06AhnUK_WuOr-nZFECcT_txc0ekAqJC_OEvZaGzcYr8CwWwjCCYO2cg3reKqV6CrF2unShmou5PdNlmFzpiNrmYlltICYZxFX-mQdn0eBXJkpxKBr_b_pD1LnBO2e0QcFI_cC6plzalWQ3RbB6daGM)
* [ë”¥ ëŸ¬ë‹ì„ ì´ìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸(Tensoflow/Keras ì‚¬ìš©)](https://wikidocs.net/book/2155)
* [Generalized Language Models](https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html#gpt)
