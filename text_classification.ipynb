{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ic4_occAAiAT"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:40.126306Z",
     "iopub.status.busy": "2020-09-23T07:21:40.125641Z",
     "iopub.status.idle": "2020-09-23T07:21:40.128216Z",
     "shell.execute_reply": "2020-09-23T07:21:40.127681Z"
    },
    "id": "ioaprt5q5US7"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:40.131917Z",
     "iopub.status.busy": "2020-09-23T07:21:40.131243Z",
     "iopub.status.idle": "2020-09-23T07:21:40.133614Z",
     "shell.execute_reply": "2020-09-23T07:21:40.133039Z"
    },
    "id": "yCl0eTNH5RS3"
   },
   "outputs": [],
   "source": [
    "#@title MIT License\n",
    "#\n",
    "# Copyright (c) 2017 François Chollet\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItXfxkxvosLH"
   },
   "source": [
    "# 영화 리뷰를 사용한 텍스트 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKY4XMc9o8iB"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/text_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />TensorFlow.org에서 보기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />깃허브(GitHub) 소스 보기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMrWLbtWaZWE"
   },
   "source": [
    "Note: 이 문서는 텐서플로 커뮤니티에서 번역했습니다. 커뮤니티 번역 활동의 특성상 정확한 번역과 최신 내용을 반영하기 위해 노력함에도\n",
    "불구하고 [공식 영문 문서](https://www.tensorflow.org/?hl=en)의 내용과 일치하지 않을 수 있습니다.\n",
    "이 번역에 개선할 부분이 있다면\n",
    "[tensorflow/docs-l10n](https://github.com/tensorflow/docs-l10n/) 깃헙 저장소로 풀 리퀘스트를 보내주시기 바랍니다.\n",
    "문서 번역이나 리뷰에 참여하려면\n",
    "[docs-ko@tensorflow.org](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-ko)로\n",
    "메일을 보내주시기 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg62Pmz3o83v"
   },
   "source": [
    "이 노트북은 영화 리뷰(review) 텍스트를 *긍정*(positive) 또는 *부정*(negative)으로 분류합니다. 이 예제는 *이진*(binary)-또는 클래스(class)가 두 개인- 분류 문제입니다. 이진 분류는 머신러닝에서 중요하고 널리 사용됩니다.\n",
    "\n",
    "여기에서는 [인터넷 영화 데이터베이스](https://www.imdb.com/)(Internet Movie Database)에서 수집한 50,000개의 영화 리뷰 텍스트를 담은 [IMDB 데이터셋](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb)을 사용하겠습니다. 25,000개 리뷰는 훈련용으로, 25,000개는 테스트용으로 나뉘어져 있습니다. 훈련 세트와 테스트 세트의 클래스는 *균형*이 잡혀 있습니다. 즉 긍정적인 리뷰와 부정적인 리뷰의 개수가 동일합니다.\n",
    "\n",
    "이 노트북은 모델을 만들고 훈련하기 위해 텐서플로의 고수준 파이썬 API인 [tf.keras](https://www.tensorflow.org/guide/keras)를 사용합니다. `tf.keras`를 사용한 고급 텍스트 분류 튜토리얼은 [MLCC 텍스트 분류 가이드](https://developers.google.com/machine-learning/guides/text-classification/)를 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:40.138081Z",
     "iopub.status.busy": "2020-09-23T07:21:40.137445Z",
     "iopub.status.idle": "2020-09-23T07:21:46.446713Z",
     "shell.execute_reply": "2020-09-23T07:21:46.447247Z"
    },
    "id": "2ew7HTbPpCJH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAsKG535pHep"
   },
   "source": [
    "## IMDB 데이터셋 다운로드\n",
    "\n",
    "IMDB 데이터셋은 텐서플로와 함께 제공됩니다. 리뷰(단어의 시퀀스(sequence))는 미리 전처리해서 정수 시퀀스로 변환되어 있습니다. 각 정수는 어휘 사전에 있는 특정 단어를 의미합니다.\n",
    "\n",
    "다음 코드는 IMDB 데이터셋을 컴퓨터에 다운로드합니다(또는 이전에 다운로드 받았다면 캐시된 복사본을 사용합니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:46.451714Z",
     "iopub.status.busy": "2020-09-23T07:21:46.451075Z",
     "iopub.status.idle": "2020-09-23T07:21:51.511011Z",
     "shell.execute_reply": "2020-09-23T07:21:51.510277Z"
    },
    "id": "zXXx5Oc3pOmN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\jeewo\\anaconda3\\envs\\zeze\\lib\\site-packages\\tensorflow_core\\python\\keras\\datasets\\imdb.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "d:\\jeewo\\anaconda3\\envs\\zeze\\lib\\site-packages\\tensorflow_core\\python\\keras\\datasets\\imdb.py:130: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "imdb = keras.datasets.imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odr-KlzO-lkL"
   },
   "source": [
    "매개변수 `num_words=10000`은 훈련 데이터에서 가장 많이 등장하는 상위 10,000개의 단어를 선택합니다. 데이터 크기를 적당하게 유지하기 위해 드물에 등장하는 단어는 제외하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l50X3GfjpU4r"
   },
   "source": [
    "## 데이터 탐색\n",
    "\n",
    "잠시 데이터 형태를 알아 보겠습니다. 이 데이터셋의 샘플은 전처리된 정수 배열입니다. 이 정수는 영화 리뷰에 나오는 단어를 나타냅니다. 레이블(label)은 정수 0 또는 1입니다. 0은 부정적인 리뷰이고 1은 긍정적인 리뷰입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:51.516259Z",
     "iopub.status.busy": "2020-09-23T07:21:51.515529Z",
     "iopub.status.idle": "2020-09-23T07:21:51.517756Z",
     "shell.execute_reply": "2020-09-23T07:21:51.518283Z"
    },
    "id": "y8qCnve_-lkO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플: 25000, 레이블: 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 샘플: {}, 레이블: {}\".format(len(train_data), len(train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnKvHWW4-lkW"
   },
   "source": [
    "리뷰 텍스트는 어휘 사전의 특정 단어를 나타내는 정수로 변환되어 있습니다. 첫 번째 리뷰를 확인해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:51.522456Z",
     "iopub.status.busy": "2020-09-23T07:21:51.521790Z",
     "iopub.status.idle": "2020-09-23T07:21:51.524067Z",
     "shell.execute_reply": "2020-09-23T07:21:51.524506Z"
    },
    "id": "QtTS4kpEpjbi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIE4l_72x7DP"
   },
   "source": [
    "영화 리뷰들은 길이가 다릅니다. 다음 코드는 첫 번째 리뷰와 두 번째 리뷰에서 단어의 개수를 출력합니다. 신경망의 입력은 길이가 같아야 하기 때문에 나중에 이 문제를 해결하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:51.533941Z",
     "iopub.status.busy": "2020-09-23T07:21:51.533232Z",
     "iopub.status.idle": "2020-09-23T07:21:51.536710Z",
     "shell.execute_reply": "2020-09-23T07:21:51.537234Z"
    },
    "id": "X-6Ii9Pfx6Nr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 189)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wJg2FiYpuoX"
   },
   "source": [
    "### 정수를 단어로 다시 변환하기\n",
    "\n",
    "정수를 다시 텍스트로 변환하는 방법이 있다면 유용할 것입니다. 여기에서는 정수와 문자열을 매핑한 딕셔너리(dictionary) 객체에 질의하는 헬퍼(helper) 함수를 만들겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:51.545348Z",
     "iopub.status.busy": "2020-09-23T07:21:51.544682Z",
     "iopub.status.idle": "2020-09-23T07:21:51.883966Z",
     "shell.execute_reply": "2020-09-23T07:21:51.884452Z"
    },
    "id": "tr5s_1alpzop"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 단어와 정수 인덱스를 매핑한 딕셔너리\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fawn': 34701,\n",
       " 'tsukino': 52006,\n",
       " 'nunnery': 52007,\n",
       " 'sonja': 16816,\n",
       " 'vani': 63951,\n",
       " 'woods': 1408,\n",
       " 'spiders': 16115,\n",
       " 'hanging': 2345,\n",
       " 'woody': 2289,\n",
       " 'trawling': 52008,\n",
       " \"hold's\": 52009,\n",
       " 'comically': 11307,\n",
       " 'localized': 40830,\n",
       " 'disobeying': 30568,\n",
       " \"'royale\": 52010,\n",
       " \"harpo's\": 40831,\n",
       " 'canet': 52011,\n",
       " 'aileen': 19313,\n",
       " 'acurately': 52012,\n",
       " \"diplomat's\": 52013,\n",
       " 'rickman': 25242,\n",
       " 'arranged': 6746,\n",
       " 'rumbustious': 52014,\n",
       " 'familiarness': 52015,\n",
       " \"spider'\": 52016,\n",
       " 'hahahah': 68804,\n",
       " \"wood'\": 52017,\n",
       " 'transvestism': 40833,\n",
       " \"hangin'\": 34702,\n",
       " 'bringing': 2338,\n",
       " 'seamier': 40834,\n",
       " 'wooded': 34703,\n",
       " 'bravora': 52018,\n",
       " 'grueling': 16817,\n",
       " 'wooden': 1636,\n",
       " 'wednesday': 16818,\n",
       " \"'prix\": 52019,\n",
       " 'altagracia': 34704,\n",
       " 'circuitry': 52020,\n",
       " 'crotch': 11585,\n",
       " 'busybody': 57766,\n",
       " \"tart'n'tangy\": 52021,\n",
       " 'burgade': 14129,\n",
       " 'thrace': 52023,\n",
       " \"tom's\": 11038,\n",
       " 'snuggles': 52025,\n",
       " 'francesco': 29114,\n",
       " 'complainers': 52027,\n",
       " 'templarios': 52125,\n",
       " '272': 40835,\n",
       " '273': 52028,\n",
       " 'zaniacs': 52130,\n",
       " '275': 34706,\n",
       " 'consenting': 27631,\n",
       " 'snuggled': 40836,\n",
       " 'inanimate': 15492,\n",
       " 'uality': 52030,\n",
       " 'bronte': 11926,\n",
       " 'errors': 4010,\n",
       " 'dialogs': 3230,\n",
       " \"yomada's\": 52031,\n",
       " \"madman's\": 34707,\n",
       " 'dialoge': 30585,\n",
       " 'usenet': 52033,\n",
       " 'videodrome': 40837,\n",
       " \"kid'\": 26338,\n",
       " 'pawed': 52034,\n",
       " \"'girlfriend'\": 30569,\n",
       " \"'pleasure\": 52035,\n",
       " \"'reloaded'\": 52036,\n",
       " \"kazakos'\": 40839,\n",
       " 'rocque': 52037,\n",
       " 'mailings': 52038,\n",
       " 'brainwashed': 11927,\n",
       " 'mcanally': 16819,\n",
       " \"tom''\": 52039,\n",
       " 'kurupt': 25243,\n",
       " 'affiliated': 21905,\n",
       " 'babaganoosh': 52040,\n",
       " \"noe's\": 40840,\n",
       " 'quart': 40841,\n",
       " 'kids': 359,\n",
       " 'uplifting': 5034,\n",
       " 'controversy': 7093,\n",
       " 'kida': 21906,\n",
       " 'kidd': 23379,\n",
       " \"error'\": 52041,\n",
       " 'neurologist': 52042,\n",
       " 'spotty': 18510,\n",
       " 'cobblers': 30570,\n",
       " 'projection': 9878,\n",
       " 'fastforwarding': 40842,\n",
       " 'sters': 52043,\n",
       " \"eggar's\": 52044,\n",
       " 'etherything': 52045,\n",
       " 'gateshead': 40843,\n",
       " 'airball': 34708,\n",
       " 'unsinkable': 25244,\n",
       " 'stern': 7180,\n",
       " \"cervi's\": 52046,\n",
       " 'dnd': 40844,\n",
       " 'dna': 11586,\n",
       " 'insecurity': 20598,\n",
       " \"'reboot'\": 52047,\n",
       " 'trelkovsky': 11037,\n",
       " 'jaekel': 52048,\n",
       " 'sidebars': 52049,\n",
       " \"sforza's\": 52050,\n",
       " 'distortions': 17633,\n",
       " 'mutinies': 52051,\n",
       " 'sermons': 30602,\n",
       " '7ft': 40846,\n",
       " 'boobage': 52052,\n",
       " \"o'bannon's\": 52053,\n",
       " 'populations': 23380,\n",
       " 'chulak': 52054,\n",
       " 'mesmerize': 27633,\n",
       " 'quinnell': 52055,\n",
       " 'yahoo': 10307,\n",
       " 'meteorologist': 52057,\n",
       " 'beswick': 42577,\n",
       " 'boorman': 15493,\n",
       " 'voicework': 40847,\n",
       " \"ster'\": 52058,\n",
       " 'blustering': 22922,\n",
       " 'hj': 52059,\n",
       " 'intake': 27634,\n",
       " 'morally': 5621,\n",
       " 'jumbling': 40849,\n",
       " 'bowersock': 52060,\n",
       " \"'porky's'\": 52061,\n",
       " 'gershon': 16821,\n",
       " 'ludicrosity': 40850,\n",
       " 'coprophilia': 52062,\n",
       " 'expressively': 40851,\n",
       " \"india's\": 19500,\n",
       " \"post's\": 34710,\n",
       " 'wana': 52063,\n",
       " 'wang': 5283,\n",
       " 'wand': 30571,\n",
       " 'wane': 25245,\n",
       " 'edgeways': 52321,\n",
       " 'titanium': 34711,\n",
       " 'pinta': 40852,\n",
       " 'want': 178,\n",
       " 'pinto': 30572,\n",
       " 'whoopdedoodles': 52065,\n",
       " 'tchaikovsky': 21908,\n",
       " 'travel': 2103,\n",
       " \"'victory'\": 52066,\n",
       " 'copious': 11928,\n",
       " 'gouge': 22433,\n",
       " \"chapters'\": 52067,\n",
       " 'barbra': 6702,\n",
       " 'uselessness': 30573,\n",
       " \"wan'\": 52068,\n",
       " 'assimilated': 27635,\n",
       " 'petiot': 16116,\n",
       " 'most\\x85and': 52069,\n",
       " 'dinosaurs': 3930,\n",
       " 'wrong': 352,\n",
       " 'seda': 52070,\n",
       " 'stollen': 52071,\n",
       " 'sentencing': 34712,\n",
       " 'ouroboros': 40853,\n",
       " 'assimilates': 40854,\n",
       " 'colorfully': 40855,\n",
       " 'glenne': 27636,\n",
       " 'dongen': 52072,\n",
       " 'subplots': 4760,\n",
       " 'kiloton': 52073,\n",
       " 'chandon': 23381,\n",
       " \"effect'\": 34713,\n",
       " 'snugly': 27637,\n",
       " 'kuei': 40856,\n",
       " 'welcomed': 9092,\n",
       " 'dishonor': 30071,\n",
       " 'concurrence': 52075,\n",
       " 'stoicism': 23382,\n",
       " \"guys'\": 14896,\n",
       " \"beroemd'\": 52077,\n",
       " 'butcher': 6703,\n",
       " \"melfi's\": 40857,\n",
       " 'aargh': 30623,\n",
       " 'playhouse': 20599,\n",
       " 'wickedly': 11308,\n",
       " 'fit': 1180,\n",
       " 'labratory': 52078,\n",
       " 'lifeline': 40859,\n",
       " 'screaming': 1927,\n",
       " 'fix': 4287,\n",
       " 'cineliterate': 52079,\n",
       " 'fic': 52080,\n",
       " 'fia': 52081,\n",
       " 'fig': 34714,\n",
       " 'fmvs': 52082,\n",
       " 'fie': 52083,\n",
       " 'reentered': 52084,\n",
       " 'fin': 30574,\n",
       " 'doctresses': 52085,\n",
       " 'fil': 52086,\n",
       " 'zucker': 12606,\n",
       " 'ached': 31931,\n",
       " 'counsil': 52088,\n",
       " 'paterfamilias': 52089,\n",
       " 'songwriter': 13885,\n",
       " 'shivam': 34715,\n",
       " 'hurting': 9654,\n",
       " 'effects': 299,\n",
       " 'slauther': 52090,\n",
       " \"'flame'\": 52091,\n",
       " 'sommerset': 52092,\n",
       " 'interwhined': 52093,\n",
       " 'whacking': 27638,\n",
       " 'bartok': 52094,\n",
       " 'barton': 8775,\n",
       " 'frewer': 21909,\n",
       " \"fi'\": 52095,\n",
       " 'ingrid': 6192,\n",
       " 'stribor': 30575,\n",
       " 'approporiately': 52096,\n",
       " 'wobblyhand': 52097,\n",
       " 'tantalisingly': 52098,\n",
       " 'ankylosaurus': 52099,\n",
       " 'parasites': 17634,\n",
       " 'childen': 52100,\n",
       " \"jenkins'\": 52101,\n",
       " 'metafiction': 52102,\n",
       " 'golem': 17635,\n",
       " 'indiscretion': 40860,\n",
       " \"reeves'\": 23383,\n",
       " \"inamorata's\": 57781,\n",
       " 'brittannica': 52104,\n",
       " 'adapt': 7916,\n",
       " \"russo's\": 30576,\n",
       " 'guitarists': 48246,\n",
       " 'abbott': 10553,\n",
       " 'abbots': 40861,\n",
       " 'lanisha': 17649,\n",
       " 'magickal': 40863,\n",
       " 'mattter': 52105,\n",
       " \"'willy\": 52106,\n",
       " 'pumpkins': 34716,\n",
       " 'stuntpeople': 52107,\n",
       " 'estimate': 30577,\n",
       " 'ugghhh': 40864,\n",
       " 'gameplay': 11309,\n",
       " \"wern't\": 52108,\n",
       " \"n'sync\": 40865,\n",
       " 'sickeningly': 16117,\n",
       " 'chiara': 40866,\n",
       " 'disturbed': 4011,\n",
       " 'portmanteau': 40867,\n",
       " 'ineffectively': 52109,\n",
       " \"duchonvey's\": 82143,\n",
       " \"nasty'\": 37519,\n",
       " 'purpose': 1285,\n",
       " 'lazers': 52112,\n",
       " 'lightened': 28105,\n",
       " 'kaliganj': 52113,\n",
       " 'popularism': 52114,\n",
       " \"damme's\": 18511,\n",
       " 'stylistics': 30578,\n",
       " 'mindgaming': 52115,\n",
       " 'spoilerish': 46449,\n",
       " \"'corny'\": 52117,\n",
       " 'boerner': 34718,\n",
       " 'olds': 6792,\n",
       " 'bakelite': 52118,\n",
       " 'renovated': 27639,\n",
       " 'forrester': 27640,\n",
       " \"lumiere's\": 52119,\n",
       " 'gaskets': 52024,\n",
       " 'needed': 884,\n",
       " 'smight': 34719,\n",
       " 'master': 1297,\n",
       " \"edie's\": 25905,\n",
       " 'seeber': 40868,\n",
       " 'hiya': 52120,\n",
       " 'fuzziness': 52121,\n",
       " 'genesis': 14897,\n",
       " 'rewards': 12607,\n",
       " 'enthrall': 30579,\n",
       " \"'about\": 40869,\n",
       " \"recollection's\": 52122,\n",
       " 'mutilated': 11039,\n",
       " 'fatherlands': 52123,\n",
       " \"fischer's\": 52124,\n",
       " 'positively': 5399,\n",
       " '270': 34705,\n",
       " 'ahmed': 34720,\n",
       " 'zatoichi': 9836,\n",
       " 'bannister': 13886,\n",
       " 'anniversaries': 52127,\n",
       " \"helm's\": 30580,\n",
       " \"'work'\": 52128,\n",
       " 'exclaimed': 34721,\n",
       " \"'unfunny'\": 52129,\n",
       " '274': 52029,\n",
       " 'feeling': 544,\n",
       " \"wanda's\": 52131,\n",
       " 'dolan': 33266,\n",
       " '278': 52133,\n",
       " 'peacoat': 52134,\n",
       " 'brawny': 40870,\n",
       " 'mishra': 40871,\n",
       " 'worlders': 40872,\n",
       " 'protags': 52135,\n",
       " 'skullcap': 52136,\n",
       " 'dastagir': 57596,\n",
       " 'affairs': 5622,\n",
       " 'wholesome': 7799,\n",
       " 'hymen': 52137,\n",
       " 'paramedics': 25246,\n",
       " 'unpersons': 52138,\n",
       " 'heavyarms': 52139,\n",
       " 'affaire': 52140,\n",
       " 'coulisses': 52141,\n",
       " 'hymer': 40873,\n",
       " 'kremlin': 52142,\n",
       " 'shipments': 30581,\n",
       " 'pixilated': 52143,\n",
       " \"'00s\": 30582,\n",
       " 'diminishing': 18512,\n",
       " 'cinematic': 1357,\n",
       " 'resonates': 14898,\n",
       " 'simplify': 40874,\n",
       " \"nature'\": 40875,\n",
       " 'temptresses': 40876,\n",
       " 'reverence': 16822,\n",
       " 'resonated': 19502,\n",
       " 'dailey': 34722,\n",
       " '2\\x85': 52144,\n",
       " 'treize': 27641,\n",
       " 'majo': 52145,\n",
       " 'kiya': 21910,\n",
       " 'woolnough': 52146,\n",
       " 'thanatos': 39797,\n",
       " 'sandoval': 35731,\n",
       " 'dorama': 40879,\n",
       " \"o'shaughnessy\": 52147,\n",
       " 'tech': 4988,\n",
       " 'fugitives': 32018,\n",
       " 'teck': 30583,\n",
       " \"'e'\": 76125,\n",
       " 'doesn’t': 40881,\n",
       " 'purged': 52149,\n",
       " 'saying': 657,\n",
       " \"martians'\": 41095,\n",
       " 'norliss': 23418,\n",
       " 'dickey': 27642,\n",
       " 'dicker': 52152,\n",
       " \"'sependipity\": 52153,\n",
       " 'padded': 8422,\n",
       " 'ordell': 57792,\n",
       " \"sturges'\": 40882,\n",
       " 'independentcritics': 52154,\n",
       " 'tempted': 5745,\n",
       " \"atkinson's\": 34724,\n",
       " 'hounded': 25247,\n",
       " 'apace': 52155,\n",
       " 'clicked': 15494,\n",
       " \"'humor'\": 30584,\n",
       " \"martino's\": 17177,\n",
       " \"'supporting\": 52156,\n",
       " 'warmongering': 52032,\n",
       " \"zemeckis's\": 34725,\n",
       " 'lube': 21911,\n",
       " 'shocky': 52157,\n",
       " 'plate': 7476,\n",
       " 'plata': 40883,\n",
       " 'sturgess': 40884,\n",
       " \"nerds'\": 40885,\n",
       " 'plato': 20600,\n",
       " 'plath': 34726,\n",
       " 'platt': 40886,\n",
       " 'mcnab': 52159,\n",
       " 'clumsiness': 27643,\n",
       " 'altogether': 3899,\n",
       " 'massacring': 42584,\n",
       " 'bicenntinial': 52160,\n",
       " 'skaal': 40887,\n",
       " 'droning': 14360,\n",
       " 'lds': 8776,\n",
       " 'jaguar': 21912,\n",
       " \"cale's\": 34727,\n",
       " 'nicely': 1777,\n",
       " 'mummy': 4588,\n",
       " \"lot's\": 18513,\n",
       " 'patch': 10086,\n",
       " 'kerkhof': 50202,\n",
       " \"leader's\": 52161,\n",
       " \"'movie\": 27644,\n",
       " 'uncomfirmed': 52162,\n",
       " 'heirloom': 40888,\n",
       " 'wrangle': 47360,\n",
       " 'emotion\\x85': 52163,\n",
       " \"'stargate'\": 52164,\n",
       " 'pinoy': 40889,\n",
       " 'conchatta': 40890,\n",
       " 'broeke': 41128,\n",
       " 'advisedly': 40891,\n",
       " \"barker's\": 17636,\n",
       " 'descours': 52166,\n",
       " 'lots': 772,\n",
       " 'lotr': 9259,\n",
       " 'irs': 9879,\n",
       " 'lott': 52167,\n",
       " 'xvi': 40892,\n",
       " 'irk': 34728,\n",
       " 'irl': 52168,\n",
       " 'ira': 6887,\n",
       " 'belzer': 21913,\n",
       " 'irc': 52169,\n",
       " 'ire': 27645,\n",
       " 'requisites': 40893,\n",
       " 'discipline': 7693,\n",
       " 'lyoko': 52961,\n",
       " 'extend': 11310,\n",
       " 'nature': 873,\n",
       " \"'dickie'\": 52170,\n",
       " 'optimist': 40894,\n",
       " 'lapping': 30586,\n",
       " 'superficial': 3900,\n",
       " 'vestment': 52171,\n",
       " 'extent': 2823,\n",
       " 'tendons': 52172,\n",
       " \"heller's\": 52173,\n",
       " 'quagmires': 52174,\n",
       " 'miyako': 52175,\n",
       " 'moocow': 20601,\n",
       " \"coles'\": 52176,\n",
       " 'lookit': 40895,\n",
       " 'ravenously': 52177,\n",
       " 'levitating': 40896,\n",
       " 'perfunctorily': 52178,\n",
       " 'lookin': 30587,\n",
       " \"lot'\": 40898,\n",
       " 'lookie': 52179,\n",
       " 'fearlessly': 34870,\n",
       " 'libyan': 52181,\n",
       " 'fondles': 40899,\n",
       " 'gopher': 35714,\n",
       " 'wearying': 40901,\n",
       " \"nz's\": 52182,\n",
       " 'minuses': 27646,\n",
       " 'puposelessly': 52183,\n",
       " 'shandling': 52184,\n",
       " 'decapitates': 31268,\n",
       " 'humming': 11929,\n",
       " \"'nother\": 40902,\n",
       " 'smackdown': 21914,\n",
       " 'underdone': 30588,\n",
       " 'frf': 40903,\n",
       " 'triviality': 52185,\n",
       " 'fro': 25248,\n",
       " 'bothers': 8777,\n",
       " \"'kensington\": 52186,\n",
       " 'much': 73,\n",
       " 'muco': 34730,\n",
       " 'wiseguy': 22615,\n",
       " \"richie's\": 27648,\n",
       " 'tonino': 40904,\n",
       " 'unleavened': 52187,\n",
       " 'fry': 11587,\n",
       " \"'tv'\": 40905,\n",
       " 'toning': 40906,\n",
       " 'obese': 14361,\n",
       " 'sensationalized': 30589,\n",
       " 'spiv': 40907,\n",
       " 'spit': 6259,\n",
       " 'arkin': 7364,\n",
       " 'charleton': 21915,\n",
       " 'jeon': 16823,\n",
       " 'boardroom': 21916,\n",
       " 'doubts': 4989,\n",
       " 'spin': 3084,\n",
       " 'hepo': 53083,\n",
       " 'wildcat': 27649,\n",
       " 'venoms': 10584,\n",
       " 'misconstrues': 52191,\n",
       " 'mesmerising': 18514,\n",
       " 'misconstrued': 40908,\n",
       " 'rescinds': 52192,\n",
       " 'prostrate': 52193,\n",
       " 'majid': 40909,\n",
       " 'climbed': 16479,\n",
       " 'canoeing': 34731,\n",
       " 'majin': 52195,\n",
       " 'animie': 57804,\n",
       " 'sylke': 40910,\n",
       " 'conditioned': 14899,\n",
       " 'waddell': 40911,\n",
       " '3\\x85': 52196,\n",
       " 'hyperdrive': 41188,\n",
       " 'conditioner': 34732,\n",
       " 'bricklayer': 53153,\n",
       " 'hong': 2576,\n",
       " 'memoriam': 52198,\n",
       " 'inventively': 30592,\n",
       " \"levant's\": 25249,\n",
       " 'portobello': 20638,\n",
       " 'remand': 52200,\n",
       " 'mummified': 19504,\n",
       " 'honk': 27650,\n",
       " 'spews': 19505,\n",
       " 'visitations': 40912,\n",
       " 'mummifies': 52201,\n",
       " 'cavanaugh': 25250,\n",
       " 'zeon': 23385,\n",
       " \"jungle's\": 40913,\n",
       " 'viertel': 34733,\n",
       " 'frenchmen': 27651,\n",
       " 'torpedoes': 52202,\n",
       " 'schlessinger': 52203,\n",
       " 'torpedoed': 34734,\n",
       " 'blister': 69876,\n",
       " 'cinefest': 52204,\n",
       " 'furlough': 34735,\n",
       " 'mainsequence': 52205,\n",
       " 'mentors': 40914,\n",
       " 'academic': 9094,\n",
       " 'stillness': 20602,\n",
       " 'academia': 40915,\n",
       " 'lonelier': 52206,\n",
       " 'nibby': 52207,\n",
       " \"losers'\": 52208,\n",
       " 'cineastes': 40916,\n",
       " 'corporate': 4449,\n",
       " 'massaging': 40917,\n",
       " 'bellow': 30593,\n",
       " 'absurdities': 19506,\n",
       " 'expetations': 53241,\n",
       " 'nyfiken': 40918,\n",
       " 'mehras': 75638,\n",
       " 'lasse': 52209,\n",
       " 'visability': 52210,\n",
       " 'militarily': 33946,\n",
       " \"elder'\": 52211,\n",
       " 'gainsbourg': 19023,\n",
       " 'hah': 20603,\n",
       " 'hai': 13420,\n",
       " 'haj': 34736,\n",
       " 'hak': 25251,\n",
       " 'hal': 4311,\n",
       " 'ham': 4892,\n",
       " 'duffer': 53259,\n",
       " 'haa': 52213,\n",
       " 'had': 66,\n",
       " 'advancement': 11930,\n",
       " 'hag': 16825,\n",
       " \"hand'\": 25252,\n",
       " 'hay': 13421,\n",
       " 'mcnamara': 20604,\n",
       " \"mozart's\": 52214,\n",
       " 'duffel': 30731,\n",
       " 'haq': 30594,\n",
       " 'har': 13887,\n",
       " 'has': 44,\n",
       " 'hat': 2401,\n",
       " 'hav': 40919,\n",
       " 'haw': 30595,\n",
       " 'figtings': 52215,\n",
       " 'elders': 15495,\n",
       " 'underpanted': 52216,\n",
       " 'pninson': 52217,\n",
       " 'unequivocally': 27652,\n",
       " \"barbara's\": 23673,\n",
       " \"bello'\": 52219,\n",
       " 'indicative': 12997,\n",
       " 'yawnfest': 40920,\n",
       " 'hexploitation': 52220,\n",
       " \"loder's\": 52221,\n",
       " 'sleuthing': 27653,\n",
       " \"justin's\": 32622,\n",
       " \"'ball\": 52222,\n",
       " \"'summer\": 52223,\n",
       " \"'demons'\": 34935,\n",
       " \"mormon's\": 52225,\n",
       " \"laughton's\": 34737,\n",
       " 'debell': 52226,\n",
       " 'shipyard': 39724,\n",
       " 'unabashedly': 30597,\n",
       " 'disks': 40401,\n",
       " 'crowd': 2290,\n",
       " 'crowe': 10087,\n",
       " \"vancouver's\": 56434,\n",
       " 'mosques': 34738,\n",
       " 'crown': 6627,\n",
       " 'culpas': 52227,\n",
       " 'crows': 27654,\n",
       " 'surrell': 53344,\n",
       " 'flowless': 52229,\n",
       " 'sheirk': 52230,\n",
       " \"'three\": 40923,\n",
       " \"peterson'\": 52231,\n",
       " 'ooverall': 52232,\n",
       " 'perchance': 40924,\n",
       " 'bottom': 1321,\n",
       " 'chabert': 53363,\n",
       " 'sneha': 52233,\n",
       " 'inhuman': 13888,\n",
       " 'ichii': 52234,\n",
       " 'ursla': 52235,\n",
       " 'completly': 30598,\n",
       " 'moviedom': 40925,\n",
       " 'raddick': 52236,\n",
       " 'brundage': 51995,\n",
       " 'brigades': 40926,\n",
       " 'starring': 1181,\n",
       " \"'goal'\": 52237,\n",
       " 'caskets': 52238,\n",
       " 'willcock': 52239,\n",
       " \"threesome's\": 52240,\n",
       " \"mosque'\": 52241,\n",
       " \"cover's\": 52242,\n",
       " 'spaceships': 17637,\n",
       " 'anomalous': 40927,\n",
       " 'ptsd': 27655,\n",
       " 'shirdan': 52243,\n",
       " 'obscenity': 21962,\n",
       " 'lemmings': 30599,\n",
       " 'duccio': 30600,\n",
       " \"levene's\": 52244,\n",
       " \"'gorby'\": 52245,\n",
       " \"teenager's\": 25255,\n",
       " 'marshall': 5340,\n",
       " 'honeymoon': 9095,\n",
       " 'shoots': 3231,\n",
       " 'despised': 12258,\n",
       " 'okabasho': 52246,\n",
       " 'fabric': 8289,\n",
       " 'cannavale': 18515,\n",
       " 'raped': 3537,\n",
       " \"tutt's\": 52247,\n",
       " 'grasping': 17638,\n",
       " 'despises': 18516,\n",
       " \"thief's\": 40928,\n",
       " 'rapes': 8926,\n",
       " 'raper': 52248,\n",
       " \"eyre'\": 27656,\n",
       " 'walchek': 52249,\n",
       " \"elmo's\": 23386,\n",
       " 'perfumes': 40929,\n",
       " 'spurting': 21918,\n",
       " \"exposition'\\x85\": 52250,\n",
       " 'denoting': 52251,\n",
       " 'thesaurus': 34740,\n",
       " \"shoot'\": 40930,\n",
       " 'bonejack': 49759,\n",
       " 'simpsonian': 52253,\n",
       " 'hebetude': 30601,\n",
       " \"hallow's\": 34741,\n",
       " 'desperation\\x85': 52254,\n",
       " 'incinerator': 34742,\n",
       " 'congratulations': 10308,\n",
       " 'humbled': 52255,\n",
       " \"else's\": 5924,\n",
       " 'trelkovski': 40845,\n",
       " \"rape'\": 52256,\n",
       " \"'chapters'\": 59386,\n",
       " '1600s': 52257,\n",
       " 'martian': 7253,\n",
       " 'nicest': 25256,\n",
       " 'eyred': 52259,\n",
       " 'passenger': 9457,\n",
       " 'disgrace': 6041,\n",
       " 'moderne': 52260,\n",
       " 'barrymore': 5120,\n",
       " 'yankovich': 52261,\n",
       " 'moderns': 40931,\n",
       " 'studliest': 52262,\n",
       " 'bedsheet': 52263,\n",
       " 'decapitation': 14900,\n",
       " 'slurring': 52264,\n",
       " \"'nunsploitation'\": 52265,\n",
       " \"'character'\": 34743,\n",
       " 'cambodia': 9880,\n",
       " 'rebelious': 52266,\n",
       " 'pasadena': 27657,\n",
       " 'crowne': 40932,\n",
       " \"'bedchamber\": 52267,\n",
       " 'conjectural': 52268,\n",
       " 'appologize': 52269,\n",
       " 'halfassing': 52270,\n",
       " 'paycheque': 57816,\n",
       " 'palms': 20606,\n",
       " \"'islands\": 52271,\n",
       " 'hawked': 40933,\n",
       " 'palme': 21919,\n",
       " 'conservatively': 40934,\n",
       " 'larp': 64007,\n",
       " 'palma': 5558,\n",
       " 'smelling': 21920,\n",
       " 'aragorn': 12998,\n",
       " 'hawker': 52272,\n",
       " 'hawkes': 52273,\n",
       " 'explosions': 3975,\n",
       " 'loren': 8059,\n",
       " \"pyle's\": 52274,\n",
       " 'shootout': 6704,\n",
       " \"mike's\": 18517,\n",
       " \"driscoll's\": 52275,\n",
       " 'cogsworth': 40935,\n",
       " \"britian's\": 52276,\n",
       " 'childs': 34744,\n",
       " \"portrait's\": 52277,\n",
       " 'chain': 3626,\n",
       " 'whoever': 2497,\n",
       " 'puttered': 52278,\n",
       " 'childe': 52279,\n",
       " 'maywether': 52280,\n",
       " 'chair': 3036,\n",
       " \"rance's\": 52281,\n",
       " 'machu': 34745,\n",
       " 'ballet': 4517,\n",
       " 'grapples': 34746,\n",
       " 'summerize': 76152,\n",
       " 'freelance': 30603,\n",
       " \"andrea's\": 52283,\n",
       " '\\x91very': 52284,\n",
       " 'coolidge': 45879,\n",
       " 'mache': 18518,\n",
       " 'balled': 52285,\n",
       " 'grappled': 40937,\n",
       " 'macha': 18519,\n",
       " 'underlining': 21921,\n",
       " 'macho': 5623,\n",
       " 'oversight': 19507,\n",
       " 'machi': 25257,\n",
       " 'verbally': 11311,\n",
       " 'tenacious': 21922,\n",
       " 'windshields': 40938,\n",
       " 'paychecks': 18557,\n",
       " 'jerk': 3396,\n",
       " \"good'\": 11931,\n",
       " 'prancer': 34748,\n",
       " 'prances': 21923,\n",
       " 'olympus': 52286,\n",
       " 'lark': 21924,\n",
       " 'embark': 10785,\n",
       " 'gloomy': 7365,\n",
       " 'jehaan': 52287,\n",
       " 'turaqui': 52288,\n",
       " \"child'\": 20607,\n",
       " 'locked': 2894,\n",
       " 'pranced': 52289,\n",
       " 'exact': 2588,\n",
       " 'unattuned': 52290,\n",
       " 'minute': 783,\n",
       " 'skewed': 16118,\n",
       " 'hodgins': 40940,\n",
       " 'skewer': 34749,\n",
       " 'think\\x85': 52291,\n",
       " 'rosenstein': 38765,\n",
       " 'helmit': 52292,\n",
       " 'wrestlemanias': 34750,\n",
       " 'hindered': 16826,\n",
       " \"martha's\": 30604,\n",
       " 'cheree': 52293,\n",
       " \"pluckin'\": 52294,\n",
       " 'ogles': 40941,\n",
       " 'heavyweight': 11932,\n",
       " 'aada': 82190,\n",
       " 'chopping': 11312,\n",
       " 'strongboy': 61534,\n",
       " 'hegemonic': 41342,\n",
       " 'adorns': 40942,\n",
       " 'xxth': 41346,\n",
       " 'nobuhiro': 34751,\n",
       " 'capitães': 52298,\n",
       " 'kavogianni': 52299,\n",
       " 'antwerp': 13422,\n",
       " 'celebrated': 6538,\n",
       " 'roarke': 52300,\n",
       " 'baggins': 40943,\n",
       " 'cheeseburgers': 31270,\n",
       " 'matras': 52301,\n",
       " \"nineties'\": 52302,\n",
       " \"'craig'\": 52303,\n",
       " 'celebrates': 12999,\n",
       " 'unintentionally': 3383,\n",
       " 'drafted': 14362,\n",
       " 'climby': 52304,\n",
       " '303': 52305,\n",
       " 'oldies': 18520,\n",
       " 'climbs': 9096,\n",
       " 'honour': 9655,\n",
       " 'plucking': 34752,\n",
       " '305': 30074,\n",
       " 'address': 5514,\n",
       " 'menjou': 40944,\n",
       " \"'freak'\": 42592,\n",
       " 'dwindling': 19508,\n",
       " 'benson': 9458,\n",
       " 'white’s': 52307,\n",
       " 'shamelessness': 40945,\n",
       " 'impacted': 21925,\n",
       " 'upatz': 52308,\n",
       " 'cusack': 3840,\n",
       " \"flavia's\": 37567,\n",
       " 'effette': 52309,\n",
       " 'influx': 34753,\n",
       " 'boooooooo': 52310,\n",
       " 'dimitrova': 52311,\n",
       " 'houseman': 13423,\n",
       " 'bigas': 25259,\n",
       " 'boylen': 52312,\n",
       " 'phillipenes': 52313,\n",
       " 'fakery': 40946,\n",
       " \"grandpa's\": 27658,\n",
       " 'darnell': 27659,\n",
       " 'undergone': 19509,\n",
       " 'handbags': 52315,\n",
       " 'perished': 21926,\n",
       " 'pooped': 37778,\n",
       " 'vigour': 27660,\n",
       " 'opposed': 3627,\n",
       " 'etude': 52316,\n",
       " \"caine's\": 11799,\n",
       " 'doozers': 52317,\n",
       " 'photojournals': 34754,\n",
       " 'perishes': 52318,\n",
       " 'constrains': 34755,\n",
       " 'migenes': 40948,\n",
       " 'consoled': 30605,\n",
       " 'alastair': 16827,\n",
       " 'wvs': 52319,\n",
       " 'ooooooh': 52320,\n",
       " 'approving': 34756,\n",
       " 'consoles': 40949,\n",
       " 'disparagement': 52064,\n",
       " 'futureistic': 52322,\n",
       " 'rebounding': 52323,\n",
       " \"'date\": 52324,\n",
       " 'gregoire': 52325,\n",
       " 'rutherford': 21927,\n",
       " 'americanised': 34757,\n",
       " 'novikov': 82196,\n",
       " 'following': 1042,\n",
       " 'munroe': 34758,\n",
       " \"morita'\": 52326,\n",
       " 'christenssen': 52327,\n",
       " 'oatmeal': 23106,\n",
       " 'fossey': 25260,\n",
       " 'livered': 40950,\n",
       " 'listens': 13000,\n",
       " \"'marci\": 76164,\n",
       " \"otis's\": 52330,\n",
       " 'thanking': 23387,\n",
       " 'maude': 16019,\n",
       " 'extensions': 34759,\n",
       " 'ameteurish': 52332,\n",
       " \"commender's\": 52333,\n",
       " 'agricultural': 27661,\n",
       " 'convincingly': 4518,\n",
       " 'fueled': 17639,\n",
       " 'mahattan': 54014,\n",
       " \"paris's\": 40952,\n",
       " 'vulkan': 52336,\n",
       " 'stapes': 52337,\n",
       " 'odysessy': 52338,\n",
       " 'harmon': 12259,\n",
       " 'surfing': 4252,\n",
       " 'halloran': 23494,\n",
       " 'unbelieveably': 49580,\n",
       " \"'offed'\": 52339,\n",
       " 'quadrant': 30607,\n",
       " 'inhabiting': 19510,\n",
       " 'nebbish': 34760,\n",
       " 'forebears': 40953,\n",
       " 'skirmish': 34761,\n",
       " 'ocassionally': 52340,\n",
       " \"'resist\": 52341,\n",
       " 'impactful': 21928,\n",
       " 'spicier': 52342,\n",
       " 'touristy': 40954,\n",
       " \"'football'\": 52343,\n",
       " 'webpage': 40955,\n",
       " 'exurbia': 52345,\n",
       " 'jucier': 52346,\n",
       " 'professors': 14901,\n",
       " 'structuring': 34762,\n",
       " 'jig': 30608,\n",
       " 'overlord': 40956,\n",
       " 'disconnect': 25261,\n",
       " 'sniffle': 82201,\n",
       " 'slimeball': 40957,\n",
       " 'jia': 40958,\n",
       " 'milked': 16828,\n",
       " 'banjoes': 40959,\n",
       " 'jim': 1237,\n",
       " 'workforces': 52348,\n",
       " 'jip': 52349,\n",
       " 'rotweiller': 52350,\n",
       " 'mundaneness': 34763,\n",
       " \"'ninja'\": 52351,\n",
       " \"dead'\": 11040,\n",
       " \"cipriani's\": 40960,\n",
       " 'modestly': 20608,\n",
       " \"professor'\": 52352,\n",
       " 'shacked': 40961,\n",
       " 'bashful': 34764,\n",
       " 'sorter': 23388,\n",
       " 'overpowering': 16120,\n",
       " 'workmanlike': 18521,\n",
       " 'henpecked': 27662,\n",
       " 'sorted': 18522,\n",
       " \"jōb's\": 52354,\n",
       " \"'always\": 52355,\n",
       " \"'baptists\": 34765,\n",
       " 'dreamcatchers': 52356,\n",
       " \"'silence'\": 52357,\n",
       " 'hickory': 21929,\n",
       " 'fun\\x97yet': 52358,\n",
       " 'breakumentary': 52359,\n",
       " 'didn': 15496,\n",
       " 'didi': 52360,\n",
       " 'pealing': 52361,\n",
       " 'dispite': 40962,\n",
       " \"italy's\": 25262,\n",
       " 'instability': 21930,\n",
       " 'quarter': 6539,\n",
       " 'quartet': 12608,\n",
       " 'padmé': 52362,\n",
       " \"'bleedmedry\": 52363,\n",
       " 'pahalniuk': 52364,\n",
       " 'honduras': 52365,\n",
       " 'bursting': 10786,\n",
       " \"pablo's\": 41465,\n",
       " 'irremediably': 52367,\n",
       " 'presages': 40963,\n",
       " 'bowlegged': 57832,\n",
       " 'dalip': 65183,\n",
       " 'entering': 6260,\n",
       " 'newsradio': 76172,\n",
       " 'presaged': 54150,\n",
       " \"giallo's\": 27663,\n",
       " 'bouyant': 40964,\n",
       " 'amerterish': 52368,\n",
       " 'rajni': 18523,\n",
       " 'leeves': 30610,\n",
       " 'macauley': 34767,\n",
       " 'seriously': 612,\n",
       " 'sugercoma': 52369,\n",
       " 'grimstead': 52370,\n",
       " \"'fairy'\": 52371,\n",
       " 'zenda': 30611,\n",
       " \"'twins'\": 52372,\n",
       " 'realisation': 17640,\n",
       " 'highsmith': 27664,\n",
       " 'raunchy': 7817,\n",
       " 'incentives': 40965,\n",
       " 'flatson': 52374,\n",
       " 'snooker': 35097,\n",
       " 'crazies': 16829,\n",
       " 'crazier': 14902,\n",
       " 'grandma': 7094,\n",
       " 'napunsaktha': 52375,\n",
       " 'workmanship': 30612,\n",
       " 'reisner': 52376,\n",
       " \"sanford's\": 61306,\n",
       " '\\x91doña': 52377,\n",
       " 'modest': 6108,\n",
       " \"everything's\": 19153,\n",
       " 'hamer': 40966,\n",
       " \"couldn't'\": 52379,\n",
       " 'quibble': 13001,\n",
       " 'socking': 52380,\n",
       " 'tingler': 21931,\n",
       " 'gutman': 52381,\n",
       " 'lachlan': 40967,\n",
       " 'tableaus': 52382,\n",
       " 'headbanger': 52383,\n",
       " 'spoken': 2847,\n",
       " 'cerebrally': 34768,\n",
       " \"'road\": 23490,\n",
       " 'tableaux': 21932,\n",
       " \"proust's\": 40968,\n",
       " 'periodical': 40969,\n",
       " \"shoveller's\": 52385,\n",
       " 'tamara': 25263,\n",
       " 'affords': 17641,\n",
       " 'concert': 3249,\n",
       " \"yara's\": 87955,\n",
       " 'someome': 52386,\n",
       " 'lingering': 8424,\n",
       " \"abraham's\": 41511,\n",
       " 'beesley': 34769,\n",
       " 'cherbourg': 34770,\n",
       " 'kagan': 28624,\n",
       " 'snatch': 9097,\n",
       " \"miyazaki's\": 9260,\n",
       " 'absorbs': 25264,\n",
       " \"koltai's\": 40970,\n",
       " 'tingled': 64027,\n",
       " 'crossroads': 19511,\n",
       " 'rehab': 16121,\n",
       " 'falworth': 52389,\n",
       " 'sequals': 52390,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3CNRvEZVppl"
   },
   "source": [
    "이제 `decode_review` 함수를 사용해 첫 번째 리뷰 텍스트를 출력할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:51.889663Z",
     "iopub.status.busy": "2020-09-23T07:21:51.888856Z",
     "iopub.status.idle": "2020-09-23T07:21:51.892147Z",
     "shell.execute_reply": "2020-09-23T07:21:51.891488Z"
    },
    "id": "s_OqxmH6-lkn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFP_XKVRp4_S"
   },
   "source": [
    "## 데이터 준비\n",
    "\n",
    "리뷰-정수 배열-는 신경망에 주입하기 전에 텐서로 변환되어야 합니다. 변환하는 방법에는 몇 가지가 있습니다:\n",
    "\n",
    "* 원-핫 인코딩(one-hot encoding)은 정수 배열을 0과 1로 이루어진 벡터로 변환합니다. 예를 들어 배열 [3, 5]을 인덱스 3과 5만 1이고 나머지는 모두 0인 10,000차원 벡터로 변환할 수 있습니다. 그다음 실수 벡터 데이터를 다룰 수 있는 층-Dense 층-을 신경망의 첫 번째 층으로 사용합니다. 이 방법은 `num_words * num_reviews` 크기의 행렬이 필요하기 때문에 메모리를 많이 사용합니다.\n",
    "* 다른 방법으로는, 정수 배열의 길이가 모두 같도록 패딩(padding)을 추가해 `max_length * num_reviews` 크기의 정수 텐서를 만듭니다. 이런 형태의 텐서를 다룰 수 있는 임베딩(embedding) 층을 신경망의 첫 번째 층으로 사용할 수 있습니다.\n",
    "\n",
    "이 튜토리얼에서는 두 번째 방식을 사용하겠습니다.\n",
    "\n",
    "영화 리뷰의 길이가 같아야 하므로 [pad_sequences](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) 함수를 사용해 길이를 맞추겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:51.901032Z",
     "iopub.status.busy": "2020-09-23T07:21:51.900342Z",
     "iopub.status.idle": "2020-09-23T07:21:52.915360Z",
     "shell.execute_reply": "2020-09-23T07:21:52.914520Z"
    },
    "id": "2jQv-omsHurp"
   },
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VO5MBpyQdipD"
   },
   "source": [
    "샘플의 길이를 확인해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:52.920484Z",
     "iopub.status.busy": "2020-09-23T07:21:52.919787Z",
     "iopub.status.idle": "2020-09-23T07:21:52.922925Z",
     "shell.execute_reply": "2020-09-23T07:21:52.922417Z"
    },
    "id": "USSSBnkE-lky"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJoxZGyfjT5V"
   },
   "source": [
    "(패딩된) 첫 번째 리뷰 내용을 확인해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:52.927715Z",
     "iopub.status.busy": "2020-09-23T07:21:52.927036Z",
     "iopub.status.idle": "2020-09-23T07:21:52.929853Z",
     "shell.execute_reply": "2020-09-23T07:21:52.929354Z"
    },
    "id": "TG8X9cqi-lk9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
      "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
      "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
      "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
      " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
      "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
      "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
      " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
      "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
      "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
      "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
      "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
      " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
      "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
      "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
      "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLC02j2g-llC"
   },
   "source": [
    "## 모델 구성\n",
    "\n",
    "신경망은 층(layer)을 쌓아서 만듭니다. 이 구조에서는 두 가지를 결정해야 합니다:\n",
    "\n",
    "* 모델에서 얼마나 많은 층을 사용할 것인가?\n",
    "* 각 층에서 얼마나 많은 *은닉 유닛*(hidden unit)을 사용할 것인가?\n",
    "\n",
    "이 예제의 입력 데이터는 단어 인덱스의 배열입니다. 예측할 레이블은 0 또는 1입니다. 이 문제에 맞는 모델을 구성해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:52.935695Z",
     "iopub.status.busy": "2020-09-23T07:21:52.934804Z",
     "iopub.status.idle": "2020-09-23T07:21:54.626430Z",
     "shell.execute_reply": "2020-09-23T07:21:54.626871Z"
    },
    "id": "xpKOoWgu-llD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 입력 크기는 영화 리뷰 데이터셋에 적용된 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "vocab_size = 10000\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PbKQ6mucuKL"
   },
   "source": [
    "층을 순서대로 쌓아 분류기(classifier)를 만듭니다:\n",
    "\n",
    "1. 첫 번째 층은 `Embedding` 층입니다. 이 층은 정수로 인코딩된 단어를 입력 받고 각 단어 인덱스에 해당하는 임베딩 벡터를 찾습니다. 이 벡터는 모델이 훈련되면서 학습됩니다. 이 벡터는 출력 배열에 새로운 차원으로 추가됩니다. 최종 차원은 `(batch, sequence, embedding)`이 됩니다.\n",
    "2. 그다음 `GlobalAveragePooling1D` 층은 `sequence` 차원에 대해 평균을 계산하여 각 샘플에 대해 고정된 길이의 출력 벡터를 반환합니다. 이는 길이가 다른 입력을 다루는 가장 간단한 방법입니다.\n",
    "3. 이 고정 길이의 출력 벡터는 16개의 은닉 유닛을 가진 완전 연결(fully-connected) 층(`Dense`)을 거칩니다.\n",
    "4. 마지막 층은 하나의 출력 노드(node)를 가진 완전 연결 층입니다. `sigmoid` 활성화 함수를 사용하여 0과 1 사이의 실수를 출력합니다. 이 값은 확률 또는 신뢰도를 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XMwnDOp-llH"
   },
   "source": [
    "### 은닉 유닛\n",
    "\n",
    "위 모델에는 입력과 출력 사이에 두 개의 중간 또는 \"은닉\" 층이 있습니다. 출력(유닛 또는 노드, 뉴런)의 개수는 층이 가진 표현 공간(representational space)의 차원이 됩니다. 다른 말로 하면, 내부 표현을 학습할 때 허용되는 네트워크 자유도의 양입니다.\n",
    "\n",
    "모델에 많은 은닉 유닛(고차원의 표현 공간)과 층이 있다면 네트워크는 더 복잡한 표현을 학습할 수 있습니다. 하지만 네트워크의 계산 비용이 많이 들고 원치않는 패턴을 학습할 수도 있습니다. 이런 표현은 훈련 데이터의 성능을 향상시키지만 테스트 데이터에서는 그렇지 못합니다. 이를 *과대적합*(overfitting)이라고 부릅니다. 나중에 이에 대해 알아 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4EqVWg4-llM"
   },
   "source": [
    "### 손실 함수와 옵티마이저\n",
    "\n",
    "모델이 훈련하려면 손실 함수(loss function)과 옵티마이저(optimizer)가 필요합니다. 이 예제는 이진 분류 문제이고 모델이 확률을 출력하므로(출력층의 유닛이 하나이고 `sigmoid` 활성화 함수를 사용합니다), `binary_crossentropy` 손실 함수를 사용하겠습니다.\n",
    "\n",
    "다른 손실 함수를 선택할 수 없는 것은 아닙니다. 예를 들어 `mean_squared_error`를 선택할 수 있습니다. 하지만 일반적으로 `binary_crossentropy`가 확률을 다루는데 적합합니다. 이 함수는 확률 분포 간의 거리를 측정합니다. 여기에서는 정답인 타깃 분포와 예측 분포 사이의 거리입니다.\n",
    "\n",
    "나중에 회귀(regression) 문제(예를 들어 주택 가격을 예측하는 문제)에 대해 살펴 볼 때 평균 제곱 오차(mean squared error) 손실 함수를 어떻게 사용하는지 알아 보겠습니다.\n",
    "\n",
    "이제 모델이 사용할 옵티마이저와 손실 함수를 설정해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:54.639995Z",
     "iopub.status.busy": "2020-09-23T07:21:54.639227Z",
     "iopub.status.idle": "2020-09-23T07:21:54.647130Z",
     "shell.execute_reply": "2020-09-23T07:21:54.646492Z"
    },
    "id": "Mr0GP-cQ-llN"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCWYwkug-llQ"
   },
   "source": [
    "## 검증 세트 만들기\n",
    "\n",
    "모델을 훈련할 때 모델이 만난 적 없는 데이터에서 정확도를 확인하는 것이 좋습니다. 원본 훈련 데이터에서 10,000개의 샘플을 떼어내어 *검증 세트*(validation set)를 만들겠습니다. (왜 테스트 세트를 사용하지 않을까요? 훈련 데이터만을 사용하여 모델을 개발하고 튜닝하는 것이 목표입니다. 그다음 테스트 세트를 사용해서 딱 한 번만 정확도를 평가합니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:54.651865Z",
     "iopub.status.busy": "2020-09-23T07:21:54.651213Z",
     "iopub.status.idle": "2020-09-23T07:21:54.653218Z",
     "shell.execute_reply": "2020-09-23T07:21:54.653608Z"
    },
    "id": "-NpcXY9--llS"
   },
   "outputs": [],
   "source": [
    "x_val = train_data[:10000]\n",
    "partial_x_train = train_data[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35jv_fzP-llU"
   },
   "source": [
    "## 모델 훈련\n",
    "\n",
    "이 모델을 512개의 샘플로 이루어진 미니배치(mini-batch)에서 40번의 에포크(epoch) 동안 훈련합니다. `x_train`과 `y_train` 텐서에 있는 모든 샘플에 대해 40번 반복한다는 뜻입니다. 훈련하는 동안 10,000개의 검증 세트에서 모델의 손실과 정확도를 모니터링합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:54.658876Z",
     "iopub.status.busy": "2020-09-23T07:21:54.658250Z",
     "iopub.status.idle": "2020-09-23T07:22:08.874375Z",
     "shell.execute_reply": "2020-09-23T07:22:08.874803Z"
    },
    "id": "tXSGrjWZ-llW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "WARNING:tensorflow:From d:\\jeewo\\anaconda3\\envs\\zeze\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001B01AC0BE58> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001B01AC0BE58> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "15000/15000 [==============================] - 1s 92us/sample - loss: 0.6920 - accuracy: 0.5164 - val_loss: 0.6901 - val_accuracy: 0.5136\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 1s 52us/sample - loss: 0.6855 - accuracy: 0.6229 - val_loss: 0.6807 - val_accuracy: 0.6934\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.6712 - accuracy: 0.7468 - val_loss: 0.6635 - val_accuracy: 0.7160\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.6476 - accuracy: 0.7463 - val_loss: 0.6366 - val_accuracy: 0.7600\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.6129 - accuracy: 0.7843 - val_loss: 0.6006 - val_accuracy: 0.7890\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.5699 - accuracy: 0.8144 - val_loss: 0.5590 - val_accuracy: 0.8096\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 1s 49us/sample - loss: 0.5229 - accuracy: 0.8354 - val_loss: 0.5158 - val_accuracy: 0.8238\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.4754 - accuracy: 0.8512 - val_loss: 0.4748 - val_accuracy: 0.8372\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 1s 51us/sample - loss: 0.4320 - accuracy: 0.8670 - val_loss: 0.4387 - val_accuracy: 0.8472\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.3938 - accuracy: 0.8753 - val_loss: 0.4084 - val_accuracy: 0.8539\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.3608 - accuracy: 0.8857 - val_loss: 0.3836 - val_accuracy: 0.8609\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.3335 - accuracy: 0.8922 - val_loss: 0.3639 - val_accuracy: 0.8653\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 1s 51us/sample - loss: 0.3101 - accuracy: 0.8975 - val_loss: 0.3499 - val_accuracy: 0.8671\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 1s 49us/sample - loss: 0.2900 - accuracy: 0.9033 - val_loss: 0.3358 - val_accuracy: 0.8717\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.2727 - accuracy: 0.9085 - val_loss: 0.3248 - val_accuracy: 0.8760\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.2580 - accuracy: 0.9136 - val_loss: 0.3163 - val_accuracy: 0.8771\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 1s 52us/sample - loss: 0.2437 - accuracy: 0.9183 - val_loss: 0.3092 - val_accuracy: 0.8798\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.2310 - accuracy: 0.9231 - val_loss: 0.3041 - val_accuracy: 0.8817\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.2201 - accuracy: 0.9263 - val_loss: 0.3003 - val_accuracy: 0.8809\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.2097 - accuracy: 0.9295 - val_loss: 0.2956 - val_accuracy: 0.8829\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 1s 51us/sample - loss: 0.1998 - accuracy: 0.9343 - val_loss: 0.2920 - val_accuracy: 0.8845\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.1907 - accuracy: 0.9368 - val_loss: 0.2896 - val_accuracy: 0.8839\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.1824 - accuracy: 0.9417 - val_loss: 0.2882 - val_accuracy: 0.8844\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.1745 - accuracy: 0.9447 - val_loss: 0.2868 - val_accuracy: 0.8849\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 1s 53us/sample - loss: 0.1673 - accuracy: 0.9475 - val_loss: 0.2865 - val_accuracy: 0.8841\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 1s 51us/sample - loss: 0.1604 - accuracy: 0.9497 - val_loss: 0.2861 - val_accuracy: 0.8851\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 1s 51us/sample - loss: 0.1544 - accuracy: 0.9523 - val_loss: 0.2859 - val_accuracy: 0.8866\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.1476 - accuracy: 0.9547 - val_loss: 0.2860 - val_accuracy: 0.8857\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 1s 58us/sample - loss: 0.1419 - accuracy: 0.9578 - val_loss: 0.2869 - val_accuracy: 0.8867\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.1360 - accuracy: 0.9605 - val_loss: 0.2881 - val_accuracy: 0.8862\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.1310 - accuracy: 0.9623 - val_loss: 0.2902 - val_accuracy: 0.8862\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 1s 51us/sample - loss: 0.1258 - accuracy: 0.9641 - val_loss: 0.2912 - val_accuracy: 0.8841\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 1s 51us/sample - loss: 0.1211 - accuracy: 0.9654 - val_loss: 0.2922 - val_accuracy: 0.8855\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.1161 - accuracy: 0.9686 - val_loss: 0.2948 - val_accuracy: 0.8854\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 1s 51us/sample - loss: 0.1115 - accuracy: 0.9699 - val_loss: 0.2970 - val_accuracy: 0.8849\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 1s 50us/sample - loss: 0.1075 - accuracy: 0.9710 - val_loss: 0.2991 - val_accuracy: 0.8842\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 1s 55us/sample - loss: 0.1034 - accuracy: 0.9731 - val_loss: 0.3015 - val_accuracy: 0.8844\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 1s 53us/sample - loss: 0.0994 - accuracy: 0.9734 - val_loss: 0.3048 - val_accuracy: 0.8841\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 1s 52us/sample - loss: 0.0956 - accuracy: 0.9749 - val_loss: 0.3076 - val_accuracy: 0.8830\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 1s 52us/sample - loss: 0.0921 - accuracy: 0.9763 - val_loss: 0.3110 - val_accuracy: 0.8822\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EEGuDVuzb5r"
   },
   "source": [
    "## 모델 평가\n",
    "\n",
    "모델의 성능을 확인해 보죠. 두 개의 값이 반환됩니다. 손실(오차를 나타내는 숫자이므로 낮을수록 좋습니다)과 정확도입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:22:08.879756Z",
     "iopub.status.busy": "2020-09-23T07:22:08.879054Z",
     "iopub.status.idle": "2020-09-23T07:22:10.410627Z",
     "shell.execute_reply": "2020-09-23T07:22:10.411068Z"
    },
    "id": "zOMKywn4zReN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/1 - 1s - loss: 0.3315 - accuracy: 0.8714\n",
      "[0.33201869685173035, 0.87136]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data,  test_labels, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1iEXVTR0Z2t"
   },
   "source": [
    "이 예제는 매우 단순한 방식을 사용하므로 87% 정도의 정확도를 달성했습니다. 고급 방법을 사용한 모델은 95%에 가까운 정확도를 얻습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KggXVeL-llZ"
   },
   "source": [
    "## 정확도와 손실 그래프 그리기\n",
    "\n",
    "`model.fit()`은 `History` 객체를 반환합니다. 여기에는 훈련하는 동안 일어난 모든 정보가 담긴 딕셔너리(dictionary)가 들어 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:22:10.415929Z",
     "iopub.status.busy": "2020-09-23T07:22:10.415051Z",
     "iopub.status.idle": "2020-09-23T07:22:10.417656Z",
     "shell.execute_reply": "2020-09-23T07:22:10.418079Z"
    },
    "id": "VcvSXvhp-llb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRKsqL40-lle"
   },
   "source": [
    "네 개의 항목이 있습니다. 훈련과 검증 단계에서 모니터링하는 지표들입니다. 훈련 손실과 검증 손실을 그래프로 그려 보고, 훈련 정확도와 검증 정확도도 그래프로 그려서 비교해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:22:10.424038Z",
     "iopub.status.busy": "2020-09-23T07:22:10.423349Z",
     "iopub.status.idle": "2020-09-23T07:22:10.732376Z",
     "shell.execute_reply": "2020-09-23T07:22:10.732967Z"
    },
    "id": "nGoYf2Js-lle"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:22:10.749404Z",
     "iopub.status.busy": "2020-09-23T07:22:10.742226Z",
     "iopub.status.idle": "2020-09-23T07:22:10.887415Z",
     "shell.execute_reply": "2020-09-23T07:22:10.888043Z"
    },
    "id": "6hXx-xOv-llh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFEmZ5zq-llk"
   },
   "source": [
    "이 그래프에서 점선은 훈련 손실과 훈련 정확도를 나타냅니다. 실선은 검증 손실과 검증 정확도입니다.\n",
    "\n",
    "훈련 손실은 에포크마다 *감소*하고 훈련 정확도는 *증가*한다는 것을 주목하세요. 경사 하강법 최적화를 사용할 때 볼 수 있는 현상입니다. 매 반복마다 최적화 대상의 값을 최소화합니다.\n",
    "\n",
    "하지만 검증 손실과 검증 정확도에서는 그렇지 못합니다. 약 20번째 에포크 이후가 최적점인 것 같습니다. 이는 과대적합 때문입니다. 이전에 본 적 없는 데이터보다 훈련 데이터에서 더 잘 동작합니다. 이 지점부터는 모델이 과도하게 최적화되어 테스트 데이터에서 *일반화*되기 어려운 훈련 데이터의 특정 표현을 학습합니다.\n",
    "\n",
    "여기에서는 과대적합을 막기 위해 단순히 20번째 에포크 근처에서 훈련을 멈출 수 있습니다. 나중에 콜백(callback)을 사용하여 자동으로 이렇게 하는 방법을 배워 보겠습니다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
